{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing initial libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from pandas_datareader import data as pdr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading and saving data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  18 of 18 completed\n",
      "[*********************100%%**********************]  18 of 18 completed\n",
      "[*********************100%%**********************]  18 of 18 completed\n"
     ]
    }
   ],
   "source": [
    "# Set up yfinance to use pandas data reader\n",
    "yf.pdr_override()\n",
    "\n",
    "# Define the list of tickers\n",
    "tickers = ['COR', 'CE', 'HUM', 'CINF', 'KEYS', 'NXPI', 'BMY', 'EMR',\n",
    "           'CVS', 'RVTY', 'ES', 'DHI', 'ZBRA', 'KMI', 'INVH', 'GPC', 'SWKS', 'GIS']\n",
    "\n",
    "# Define the date range\n",
    "start_date = '2002-01-01'\n",
    "end_date = '2022-12-31'\n",
    "Output_file = 'stock_prices.xlsx'\n",
    "\n",
    "# Create a pandas DataFrame to store the data\n",
    "price_data = pdr.get_data_yahoo(\n",
    "    tickers, start=start_date, end=end_date)['Close']\n",
    "adj_price_data = pdr.get_data_yahoo(\n",
    "    tickers, start=start_date, end=end_date)['Adj Close']\n",
    "volume_data = pdr.get_data_yahoo(\n",
    "    tickers, start=start_date, end=end_date)['Volume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the datetime index to string in the format \"MM/DD/YYYY\"\n",
    "price_data.index = price_data.index.strftime('%m/%d/%Y')\n",
    "adj_price_data.index = adj_price_data.index.strftime('%m/%d/%Y')\n",
    "volume_data.index = volume_data.index.strftime('%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock prices saved to stock_prices.xlsx\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create an Excel writer\n",
    "with pd.ExcelWriter(Output_file, engine='openpyxl') as writer:\n",
    "    # Save close prices to \"Price_daily\" sheet\n",
    "    price_data.to_excel(writer, sheet_name='Price_daily')\n",
    "\n",
    "    # Save adjusted close prices to \"Adj_Price_daily\" sheet\n",
    "    adj_price_data.to_excel(writer, sheet_name='Adj_Price_daily')\n",
    "\n",
    "    # Save volume data to \"Volume_daily\" sheet\n",
    "    volume_data.to_excel(writer, sheet_name='Volume_daily')\n",
    "\n",
    "print(\"Stock prices saved to stock_prices.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "Prices for the S&P 500 index (^GSPC) saved to stock_prices.xlsx\n"
     ]
    }
   ],
   "source": [
    "sp500_data = pdr.get_data_yahoo('^GSPC', start=start_date, end=end_date)[\n",
    "    [\"Adj Close\", \"Close\", \"High\", \"Low\", \"Open\", \"Volume\"]]\n",
    "sp500_data.index = sp500_data.index.strftime('%m/%d/%Y')\n",
    "\n",
    "with pd.ExcelWriter(Output_file, engine='openpyxl', mode='a', if_sheet_exists=\"replace\") as writer:\n",
    "    sp500_data.to_excel(writer, sheet_name='S&P 500')\n",
    "print(\"Prices for the S&P 500 index (^GSPC) saved to stock_prices.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Market Captilization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Market capitalization data added to the Excel file.\n",
      "          Date           COR            CE           HUM          CINF  \\\n",
      "0   2002-12-31  2.095852e+09           NaN  1.107811e+09  2.546110e+09   \n",
      "1   2003-12-31  2.216050e+09           NaN  2.531348e+09  2.904207e+09   \n",
      "2   2004-12-31  2.272264e+09           NaN  3.289091e+09  3.317503e+09   \n",
      "3   2005-12-30  3.211911e+09  1.605232e+09  6.018738e+09  3.619248e+09   \n",
      "4   2006-12-29  3.497818e+09  2.190745e+09  6.127303e+09  3.778134e+09   \n",
      "5   2007-12-31  3.614503e+09  3.599709e+09  8.342921e+09  3.408416e+09   \n",
      "6   2008-12-31  2.897552e+09  1.062671e+09  4.129920e+09  2.632863e+09   \n",
      "7   2009-12-31  4.286257e+09  2.768339e+09  4.862182e+09  2.538390e+09   \n",
      "8   2010-12-31  5.674672e+09  3.571045e+09  6.064158e+09  3.235818e+09   \n",
      "9   2011-12-30  6.259213e+09  3.858797e+09  9.793616e+09  3.284150e+09   \n",
      "10  2012-12-31  7.382486e+09  3.906718e+09  7.777372e+09  4.408008e+09   \n",
      "11  2013-12-31  1.220708e+10  4.902934e+09  1.184524e+10  6.104032e+09   \n",
      "12  2014-12-31  1.586360e+10  5.402107e+09  1.662551e+10  6.264233e+09   \n",
      "13  2015-12-31  1.846303e+10  6.174733e+09  2.079344e+10  7.456094e+09   \n",
      "14  2016-12-30  1.415702e+10  7.373794e+09  2.388171e+10  9.807514e+09   \n",
      "15  2017-12-29  1.691945e+10  1.021393e+10  2.927992e+10  1.003695e+10   \n",
      "16  2018-12-31  1.394677e+10  8.752727e+09  3.404446e+10  1.066469e+10   \n",
      "17  2019-12-31  1.624530e+10  1.224085e+10  4.389573e+10  1.481030e+10   \n",
      "18  2020-12-31  1.901238e+10  1.325104e+10  4.947423e+10  1.271537e+10   \n",
      "19  2021-12-31  2.623972e+10  1.745802e+10  5.630080e+10  1.694655e+10   \n",
      "20  2022-12-30  3.313085e+10  1.086346e+10  6.258040e+10  1.560942e+10   \n",
      "\n",
      "            KEYS          NXPI           BMY           EMR           CVS  \\\n",
      "0            NaN           NaN  2.131470e+10  8.020547e+09  1.121660e+10   \n",
      "1            NaN           NaN  2.752512e+10  1.053251e+10  1.636345e+10   \n",
      "2            NaN           NaN  2.553197e+10  1.170124e+10  2.055475e+10   \n",
      "3            NaN           NaN  2.396398e+10  1.278058e+10  2.423176e+10   \n",
      "4            NaN           NaN  2.873279e+10  1.542289e+10  2.849862e+10   \n",
      "5            NaN           NaN  3.011118e+10  2.027261e+10  3.688447e+10   \n",
      "6            NaN           NaN  2.829585e+10  1.346725e+10  2.686503e+10   \n",
      "7            NaN           NaN  3.249085e+10  1.625686e+10  3.040347e+10   \n",
      "8            NaN  4.967267e+09  3.532892e+10  2.240927e+10  3.317529e+10   \n",
      "9            NaN  3.647725e+09  4.926115e+10  1.877183e+10  3.945898e+10   \n",
      "10           NaN  6.246462e+09  4.738676e+10  2.203113e+10  4.746202e+10   \n",
      "11           NaN  1.090046e+10  8.053760e+10  2.999823e+10  7.137444e+10   \n",
      "12  5.996698e+09  1.813183e+10  9.195774e+10  2.711255e+10  9.747181e+10   \n",
      "13  5.030691e+09  1.999485e+10  1.096651e+11  2.176672e+10  1.002998e+11   \n",
      "14  6.493907e+09  2.326048e+10  9.487006e+10  2.633910e+10  8.241591e+10   \n",
      "15  7.387107e+09  2.778869e+10  1.021835e+11  3.399055e+10  7.767514e+10   \n",
      "16  1.102384e+10  1.749271e+10  8.900621e+10  2.995502e+10  7.220969e+10   \n",
      "17  1.822449e+10  3.073920e+10  1.136948e+11  3.940129e+10  8.467317e+10   \n",
      "18  2.345584e+10  3.891680e+10  1.141603e+11  4.279321e+10  8.032012e+10   \n",
      "19  3.667095e+10  5.636227e+10  1.174480e+11  5.057943e+10  1.243910e+11   \n",
      "20  3.037771e+10  3.989635e+10  1.397408e+11  5.348048e+10  1.149051e+11   \n",
      "\n",
      "            RVTY            ES           DHI          ZBRA           KMI  \\\n",
      "0   8.435058e+08  6.094709e+09  2.183110e+09  1.307958e+09           NaN   \n",
      "1   1.788370e+09  8.388451e+09  5.503329e+09  2.272491e+09           NaN   \n",
      "2   2.392435e+09  8.105562e+09  7.779089e+09  2.890518e+09           NaN   \n",
      "3   2.540495e+09  8.769883e+09  9.288611e+09  2.200759e+09           NaN   \n",
      "4   2.428695e+09  1.296026e+10  7.021144e+09  1.786801e+09           NaN   \n",
      "5   2.873960e+09  1.479045e+10  3.607438e+09  1.782178e+09           NaN   \n",
      "6   1.553902e+09  1.173875e+10  1.989492e+09  1.040546e+09           NaN   \n",
      "7   2.340896e+09  1.312131e+10  3.106704e+09  1.456045e+09           NaN   \n",
      "8   2.973752e+09  1.682605e+10  3.454118e+09  1.951151e+09           NaN   \n",
      "9   2.330637e+09  1.965312e+10  3.701381e+09  1.837646e+09  3.982226e+10   \n",
      "10  3.739170e+09  2.206684e+10  5.904098e+09  2.018946e+09  4.546000e+10   \n",
      "11  4.896628e+09  2.480603e+10  6.662258e+09  2.777527e+09  4.827369e+10   \n",
      "12  5.227276e+09  3.240140e+10  7.616355e+09  3.975747e+09  5.946752e+10   \n",
      "13  6.440604e+09  3.198600e+10  9.738882e+09  3.577196e+09  2.214071e+10   \n",
      "14  6.304004e+09  3.574845e+10  8.407819e+09  4.404599e+09  3.160103e+10   \n",
      "15  8.879171e+09  4.217240e+10  1.589545e+10  5.331127e+09  2.826267e+10   \n",
      "16  9.572075e+09  4.487504e+10  1.092589e+10  8.177989e+09  2.510152e+10   \n",
      "17  1.187001e+10  6.035204e+10  1.685755e+10  1.311930e+10  3.625344e+10   \n",
      "18  1.759126e+10  6.303716e+10  2.229129e+10  1.973903e+10  2.510075e+10   \n",
      "19  2.469294e+10  6.819691e+10  3.538379e+10  3.056923e+10  3.106388e+10   \n",
      "20  1.725321e+10  6.474643e+10  2.942800e+10  1.316912e+10  3.766051e+10   \n",
      "\n",
      "            INVH           GPC          SWKS           GIS  \n",
      "0            NaN  2.239031e+09  1.176511e+09  7.150415e+09  \n",
      "1            NaN  2.506143e+09  1.187430e+09  7.064209e+09  \n",
      "2            NaN  3.430648e+09  1.287065e+09  7.952939e+09  \n",
      "3            NaN  3.518453e+09  6.947145e+08  8.048897e+09  \n",
      "4            NaN  3.918921e+09  9.663219e+08  9.653592e+09  \n",
      "5            NaN  3.941624e+09  1.160133e+09  9.807520e+09  \n",
      "6            NaN  3.349000e+09  7.561333e+08  1.073833e+10  \n",
      "7            NaN  3.523401e+09  1.936739e+09  1.291040e+10  \n",
      "8            NaN  4.951028e+09  3.907599e+09  1.336287e+10  \n",
      "9            NaN  6.102565e+09  2.213806e+09  1.566041e+10  \n",
      "10           NaN  6.545720e+09  2.770668e+09  1.617268e+10  \n",
      "11           NaN  8.807202e+09  3.898045e+09  2.058799e+10  \n",
      "12           NaN  1.157360e+10  9.992763e+09  2.270274e+10  \n",
      "13           NaN  9.589764e+09  1.065649e+10  2.532357e+10  \n",
      "14           NaN  1.096107e+10  1.052705e+10  2.793424e+10  \n",
      "15  1.249996e+10  1.122965e+10  1.354699e+10  2.775240e+10  \n",
      "16  1.086295e+10  1.169126e+10  9.712858e+09  1.899092e+10  \n",
      "17  1.654135e+10  1.333386e+10  1.788168e+10  2.718136e+10  \n",
      "18  1.673771e+10  1.304130e+10  2.295293e+10  3.087705e+10  \n",
      "19  2.604062e+10  1.869989e+10  2.357880e+10  3.659734e+10  \n",
      "20  1.743648e+10  2.371557e+10  1.415996e+10  4.687838e+10  \n",
      "Annual maket capital saved to stock_prices.xlsx\n"
     ]
    }
   ],
   "source": [
    "from Market_Cap import cal_market_cap, filter_last_date_per_year\n",
    "\n",
    "constituents_file = \"S&P 500 Constituent.xlsx\"\n",
    "constituents_data = pd.read_excel(\n",
    "    constituents_file, sheet_name=\"S&P 500 Constituent\")\n",
    "cal_market_cap(start_date, end_date, constituents_file, Output_file, tickers)\n",
    "\n",
    "\n",
    "sheet_name = 'Market_Caps'\n",
    "filtered_df = filter_last_date_per_year(Output_file, sheet_name)\n",
    "\n",
    "\n",
    "with pd.ExcelWriter(Output_file, engine='openpyxl', mode='a', if_sheet_exists=\"replace\") as writer:\n",
    "    filtered_df.to_excel(writer, sheet_name='Market_Caps')\n",
    "\n",
    "print(\"Annual maket capital saved to stock_prices.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating annual liquidity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculateing the sum of daily Volume for each firm per year, dividing it by the total shares outstanding, and saving it in the sheet “Liquidity_annual”. This is a measure of how frequently a stock is traded, and generally, it is perceived as a measure of its liquidity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CE: Data doesn't exist for startDate = 1009861200, endDate = 1041310800\n",
      "KEYS: Data doesn't exist for startDate = 1009861200, endDate = 1041310800\n",
      "NXPI: Data doesn't exist for startDate = 1009861200, endDate = 1041310800\n",
      "KMI: Data doesn't exist for startDate = 1009861200, endDate = 1041310800\n",
      "INVH: Data doesn't exist for startDate = 1009861200, endDate = 1041310800\n",
      "CE: Data doesn't exist for startDate = 1041397200, endDate = 1072846800\n",
      "KEYS: Data doesn't exist for startDate = 1041397200, endDate = 1072846800\n",
      "NXPI: Data doesn't exist for startDate = 1041397200, endDate = 1072846800\n",
      "KMI: Data doesn't exist for startDate = 1041397200, endDate = 1072846800\n",
      "INVH: Data doesn't exist for startDate = 1041397200, endDate = 1072846800\n",
      "CE: Data doesn't exist for startDate = 1072933200, endDate = 1104469200\n",
      "KEYS: Data doesn't exist for startDate = 1072933200, endDate = 1104469200\n",
      "NXPI: Data doesn't exist for startDate = 1072933200, endDate = 1104469200\n",
      "KMI: Data doesn't exist for startDate = 1072933200, endDate = 1104469200\n",
      "INVH: Data doesn't exist for startDate = 1072933200, endDate = 1104469200\n",
      "KEYS: Data doesn't exist for startDate = 1104555600, endDate = 1136005200\n",
      "NXPI: Data doesn't exist for startDate = 1104555600, endDate = 1136005200\n",
      "KMI: Data doesn't exist for startDate = 1104555600, endDate = 1136005200\n",
      "INVH: Data doesn't exist for startDate = 1104555600, endDate = 1136005200\n",
      "KEYS: Data doesn't exist for startDate = 1136091600, endDate = 1167541200\n",
      "NXPI: Data doesn't exist for startDate = 1136091600, endDate = 1167541200\n",
      "KMI: Data doesn't exist for startDate = 1136091600, endDate = 1167541200\n",
      "INVH: Data doesn't exist for startDate = 1136091600, endDate = 1167541200\n",
      "KEYS: Data doesn't exist for startDate = 1167627600, endDate = 1199077200\n",
      "NXPI: Data doesn't exist for startDate = 1167627600, endDate = 1199077200\n",
      "KMI: Data doesn't exist for startDate = 1167627600, endDate = 1199077200\n",
      "INVH: Data doesn't exist for startDate = 1167627600, endDate = 1199077200\n",
      "KEYS: Data doesn't exist for startDate = 1199163600, endDate = 1230699600\n",
      "NXPI: Data doesn't exist for startDate = 1199163600, endDate = 1230699600\n",
      "KMI: Data doesn't exist for startDate = 1199163600, endDate = 1230699600\n",
      "INVH: Data doesn't exist for startDate = 1199163600, endDate = 1230699600\n",
      "KEYS: Data doesn't exist for startDate = 1230786000, endDate = 1262235600\n",
      "NXPI: Data doesn't exist for startDate = 1230786000, endDate = 1262235600\n",
      "KMI: Data doesn't exist for startDate = 1230786000, endDate = 1262235600\n",
      "INVH: Data doesn't exist for startDate = 1230786000, endDate = 1262235600\n",
      "KEYS: Data doesn't exist for startDate = 1262322000, endDate = 1293771600\n",
      "KMI: Data doesn't exist for startDate = 1262322000, endDate = 1293771600\n",
      "INVH: Data doesn't exist for startDate = 1262322000, endDate = 1293771600\n",
      "KEYS: Data doesn't exist for startDate = 1293858000, endDate = 1325307600\n",
      "INVH: Data doesn't exist for startDate = 1293858000, endDate = 1325307600\n",
      "KEYS: Data doesn't exist for startDate = 1325394000, endDate = 1356930000\n",
      "INVH: Data doesn't exist for startDate = 1325394000, endDate = 1356930000\n",
      "KEYS: Data doesn't exist for startDate = 1357016400, endDate = 1388466000\n",
      "INVH: Data doesn't exist for startDate = 1357016400, endDate = 1388466000\n",
      "INVH: Data doesn't exist for startDate = 1388552400, endDate = 1420002000\n",
      "INVH: Data doesn't exist for startDate = 1420088400, endDate = 1451538000\n",
      "INVH: Data doesn't exist for startDate = 1451624400, endDate = 1483160400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liquidity data added to the Excel file.\n"
     ]
    }
   ],
   "source": [
    "from liquidity import cal_liquidity\n",
    "excel_file = \"Stock Data Output.xlsx\"  # Replace with your file path\n",
    "sheet_name = \"Liquidity_annual\"\n",
    "constituents_data = constituents_data[[\"ticker\", \"Name\", \"Share_outstanding\"]]\n",
    "cal_liquidity(Output_file, tickers, constituents_data, sheet_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating returns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using adjusted close prices at the annual, monthly, and daily frequencies, computing the annual, monthly, and daily returns. Saving them in new sheets labeled “Returns_annual”, “Returns_monthly”, and “Returns_daily”.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "def download_data(ticker, start_date, end_date):\n",
    "    benchmark_symbol = \"^GSPC\"\n",
    "    stock_data = yf.download(ticker, start=start_date, end=end_date)\n",
    "    benchmark_data = yf.download(\n",
    "        benchmark_symbol, start=start_date, end=end_date)\n",
    "    return stock_data, benchmark_data\n",
    "\n",
    "\n",
    "for ticker in tickers:\n",
    "    data, benchmark_data = download_data(ticker, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data download, Excel file update, and returns calculation completed.\n"
     ]
    }
   ],
   "source": [
    "from returns import cal_returns\n",
    "\n",
    "cal_returns(Output_file, tickers, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating annual risks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using Returtns_daily, calculating the standard deviation of each stock in each year. Saving these in a new sheet called “Risk_annual”.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data download, Excel file update, returns calculation, and risk calculation completed.\n"
     ]
    }
   ],
   "source": [
    "from risk import cal_risks\n",
    "\n",
    "cal_risks(Output_file, tickers, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating statistics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calcuating summary statistics of our portfolio holdings (in sheet “Firm_Summary_Stat”)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from beta import cal_beta_main, calculate_beta\n",
    "\n",
    "# Load the data from Excel file\n",
    "returns_sheet_name = 'Returns_annual'\n",
    "constituents_sheet_name = 'S&P 500 Constituent'\n",
    "\n",
    "returns_data = pd.read_excel(\n",
    "    Output_file, sheet_name=returns_sheet_name, index_col=0)\n",
    "constituents_data = pd.read_excel(\n",
    "    \"S&P 500 Constituent.xlsx\", sheet_name=constituents_sheet_name, index_col=0)\n",
    "\n",
    "# Filter returns data for the last 5 years (2018:2022)\n",
    "returns_data_last_5_years = returns_data.loc['2018-01-01':'2022-12-31']\n",
    "\n",
    "# Create a new DataFrame for summary statistics\n",
    "summary_stats_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "# Calculate and add summary statistics for each firm\n",
    "summary_stats_df['Min'] = returns_data_last_5_years.min()\n",
    "summary_stats_df['Max'] = returns_data_last_5_years.max()\n",
    "summary_stats_df['Mean'] = returns_data_last_5_years.mean()\n",
    "summary_stats_df['Volatility'] = returns_data_last_5_years.std()\n",
    "\n",
    "# Load market capitalization data\n",
    "market_cap_data = pd.read_excel(\n",
    "    Output_file, sheet_name=\"Market_Caps\", index_col=0)\n",
    "\n",
    "# Add market capitalization (size) for each firm to the summary_stats_df\n",
    "# You can use mean() or any other aggregation method\n",
    "summary_stats_df['Size'] = market_cap_data.mean()\n",
    "\n",
    "\n",
    "# Add industry information for each firm\n",
    "summary_stats_df['Industry'] = constituents_data['GICS Sector']\n",
    "\n",
    "# Add a new sheet \"Firm_Summary_Stat\" to the existing Excel file\n",
    "with pd.ExcelWriter(Output_file, engine=\"openpyxl\", mode=\"a\", if_sheet_exists=\"replace\") as writer:\n",
    "    summary_stats_df.T.to_excel(\n",
    "        writer, sheet_name=\"Firm_Summary_Stat\", index=True, header=True)\n",
    "\n",
    "\n",
    "cal_beta_main(tickers, data, benchmark_data, start_date, end_date,\n",
    "              constituents_file, Output_file, summary_stats_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Personal Portfolio Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Strategy = Return: Every January, invest more in firms that had a larger return last year. If they had negative returns, do not invest in them this year.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  18 of 18 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\Coding Projects\\Refined\\Financial Modelling-Yahoo Finance\\portfolio_analysis.py:29: FutureWarning: The argument 'date_parser' is deprecated and will be removed in a future version. Please use 'date_format' instead, or read your data in as 'object' dtype and then call 'to_datetime'.\n",
      "  FF_3Factor_All = pdr.get_data_famafrench(\n",
      "d:\\Projects\\Coding Projects\\Refined\\Financial Modelling-Yahoo Finance\\portfolio_analysis.py:29: FutureWarning: The argument 'date_parser' is deprecated and will be removed in a future version. Please use 'date_format' instead, or read your data in as 'object' dtype and then call 'to_datetime'.\n",
      "  FF_3Factor_All = pdr.get_data_famafrench(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: -1.342083\n",
      "         Iterations: 19\n",
      "         Function evaluations: 468\n",
      "         Gradient evaluations: 26\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Stock Data Output.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mportfolio_analysis\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cal_portfolio\n\u001b[1;32m----> 3\u001b[0m combined_returns, Rf \u001b[38;5;241m=\u001b[39m \u001b[43mcal_portfolio\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtickers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOutput_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Projects\\Coding Projects\\Refined\\Financial Modelling-Yahoo Finance\\portfolio_analysis.py:118\u001b[0m, in \u001b[0;36mcal_portfolio\u001b[1;34m(tickers, output_file_path)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;66;03m# Save the output to an existing Excel file with the plots\u001b[39;00m\n\u001b[0;32m    117\u001b[0m output_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStock Data Output.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 118\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mExcelWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mopenpyxl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ma\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_sheet_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreplace\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m writer:\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;66;03m# Save the combined returns to the sheet \"PortfolioReturn_monthly\"\u001b[39;00m\n\u001b[0;32m    120\u001b[0m     combined_returns\u001b[38;5;241m.\u001b[39mto_excel(\n\u001b[0;32m    121\u001b[0m         writer, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, sheet_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPortfolioReturn_monthly\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;66;03m# Save the bar chart image to the same worksheet\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\saif_\\miniconda3\\lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:60\u001b[0m, in \u001b[0;36mOpenpyxlWriter.__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenpyxl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mworkbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Workbook\n\u001b[0;32m     58\u001b[0m engine_kwargs \u001b[38;5;241m=\u001b[39m combine_kwargs(engine_kwargs, kwargs)\n\u001b[1;32m---> 60\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43mif_sheet_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_sheet_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# ExcelWriter replaced \"a\" by \"r+\" to allow us to first read the excel file from\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# the file and later write to it\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode:  \u001b[38;5;66;03m# Load from existing workbook\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\saif_\\miniconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1219\u001b[0m, in \u001b[0;36mExcelWriter.__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs)\u001b[0m\n\u001b[0;32m   1215\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handles \u001b[38;5;241m=\u001b[39m IOHandles(\n\u001b[0;32m   1216\u001b[0m     cast(IO[\u001b[38;5;28mbytes\u001b[39m], path), compression\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[0;32m   1217\u001b[0m )\n\u001b[0;32m   1218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, ExcelWriter):\n\u001b[1;32m-> 1219\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1220\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1222\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cur_sheet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m date_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\saif_\\miniconda3\\lib\\site-packages\\pandas\\io\\common.py:868\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    869\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    871\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Stock Data Output.xlsx'"
     ]
    }
   ],
   "source": [
    "from portfolio_analysis import cal_portfolio\n",
    "\n",
    "combined_returns, Rf = cal_portfolio(\n",
    "    tickers, Output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating portfolio performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from portfolio_perf import cal_portfolio_perf\n",
    "\n",
    "cal_portfolio_perf(combined_returns, Rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Portfolio Returns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from portfolio_return import cal_portfolio_return\n",
    "\n",
    "cal_portfolio_return(combined_returns, Rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating investment summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from invest_sum import cal_invest_sum\n",
    "\n",
    "cal_invest_sum(tickers, Rf, combined_returns, constituents_file, Output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making excel file more readalbe.\n",
    "\n",
    "###### (This is the last step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wraping Text\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
