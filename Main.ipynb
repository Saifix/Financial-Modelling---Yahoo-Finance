{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing initial libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from pandas_datareader import data as pdr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading and saving data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  18 of 18 completed\n",
      "[*********************100%%**********************]  18 of 18 completed\n",
      "[*********************100%%**********************]  18 of 18 completed\n"
     ]
    }
   ],
   "source": [
    "# Set up yfinance to use pandas data reader\n",
    "yf.pdr_override()\n",
    "\n",
    "# Define the list of tickers\n",
    "tickers = ['COR', 'CE', 'HUM', 'CINF', 'KEYS', 'NXPI', 'BMY', 'EMR',\n",
    "           'CVS', 'RVTY', 'ES', 'DHI', 'ZBRA', 'KMI', 'INVH', 'GPC', 'SWKS', 'GIS']\n",
    "\n",
    "# Define the date range\n",
    "start_date = '2002-01-01'\n",
    "end_date = '2022-12-31'\n",
    "Output_file = 'stock_prices.xlsx'\n",
    "\n",
    "# Create a pandas DataFrame to store the data\n",
    "price_data = pdr.get_data_yahoo(\n",
    "    tickers, start=start_date, end=end_date)['Close']\n",
    "adj_price_data = pdr.get_data_yahoo(\n",
    "    tickers, start=start_date, end=end_date)['Adj Close']\n",
    "volume_data = pdr.get_data_yahoo(\n",
    "    tickers, start=start_date, end=end_date)['Volume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the datetime index to string in the format \"MM/DD/YYYY\"\n",
    "price_data.index = price_data.index.strftime('%m/%d/%Y')\n",
    "adj_price_data.index = adj_price_data.index.strftime('%m/%d/%Y')\n",
    "volume_data.index = volume_data.index.strftime('%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock prices saved to stock_prices.xlsx\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create an Excel writer\n",
    "with pd.ExcelWriter(Output_file, engine='openpyxl') as writer:\n",
    "    # Save close prices to \"Price_daily\" sheet\n",
    "    price_data.to_excel(writer, sheet_name='Price_daily')\n",
    "\n",
    "    # Save adjusted close prices to \"Adj_Price_daily\" sheet\n",
    "    adj_price_data.to_excel(writer, sheet_name='Adj_Price_daily')\n",
    "\n",
    "    # Save volume data to \"Volume_daily\" sheet\n",
    "    volume_data.to_excel(writer, sheet_name='Volume_daily')\n",
    "\n",
    "print(\"Stock prices saved to stock_prices.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "Prices for the S&P 500 index (^GSPC) saved to stock_prices.xlsx\n"
     ]
    }
   ],
   "source": [
    "sp500_data = pdr.get_data_yahoo('^GSPC', start=start_date, end=end_date)[\n",
    "    [\"Adj Close\", \"Close\", \"High\", \"Low\", \"Open\", \"Volume\"]]\n",
    "sp500_data.index = sp500_data.index.strftime('%m/%d/%Y')\n",
    "\n",
    "with pd.ExcelWriter(Output_file, engine='openpyxl', mode='a', if_sheet_exists=\"replace\") as writer:\n",
    "    sp500_data.to_excel(writer, sheet_name='S&P 500')\n",
    "print(\"Prices for the S&P 500 index (^GSPC) saved to stock_prices.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Market Captilization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Market capitalization data added to the Excel file.\n",
      "          Date           COR            CE           HUM          CINF  \\\n",
      "0   2002-12-31  2.095852e+09           NaN  1.107811e+09  2.546112e+09   \n",
      "1   2003-12-31  2.216050e+09           NaN  2.531348e+09  2.904206e+09   \n",
      "2   2004-12-31  2.272264e+09           NaN  3.289091e+09  3.317501e+09   \n",
      "3   2005-12-30  3.211910e+09  1.605231e+09  6.018737e+09  3.619250e+09   \n",
      "4   2006-12-29  3.497819e+09  2.190745e+09  6.127303e+09  3.778132e+09   \n",
      "5   2007-12-31  3.614503e+09  3.599710e+09  8.342924e+09  3.408418e+09   \n",
      "6   2008-12-31  2.897552e+09  1.062671e+09  4.129920e+09  2.632866e+09   \n",
      "7   2009-12-31  4.286258e+09  2.768340e+09  4.862182e+09  2.538392e+09   \n",
      "8   2010-12-31  5.674674e+09  3.571043e+09  6.064158e+09  3.235817e+09   \n",
      "9   2011-12-30  6.259214e+09  3.858797e+09  9.793612e+09  3.284151e+09   \n",
      "10  2012-12-31  7.382486e+09  3.906720e+09  7.777371e+09  4.408008e+09   \n",
      "11  2013-12-31  1.220708e+10  4.902935e+09  1.184524e+10  6.104034e+09   \n",
      "12  2014-12-31  1.586359e+10  5.402106e+09  1.662552e+10  6.264233e+09   \n",
      "13  2015-12-31  1.846302e+10  6.174732e+09  2.079344e+10  7.456092e+09   \n",
      "14  2016-12-30  1.415703e+10  7.373790e+09  2.388171e+10  9.807517e+09   \n",
      "15  2017-12-29  1.691945e+10  1.021393e+10  2.927993e+10  1.003695e+10   \n",
      "16  2018-12-31  1.394677e+10  8.752727e+09  3.404445e+10  1.066469e+10   \n",
      "17  2019-12-31  1.624530e+10  1.224085e+10  4.389575e+10  1.481030e+10   \n",
      "18  2020-12-31  1.901238e+10  1.325104e+10  4.947422e+10  1.271537e+10   \n",
      "19  2021-12-31  2.623972e+10  1.745802e+10  5.630080e+10  1.694655e+10   \n",
      "20  2022-12-30  3.313085e+10  1.086346e+10  6.258040e+10  1.560942e+10   \n",
      "\n",
      "            KEYS          NXPI           BMY           EMR           CVS  \\\n",
      "0            NaN           NaN  2.131470e+10  8.020544e+09  1.121660e+10   \n",
      "1            NaN           NaN  2.752511e+10  1.053251e+10  1.636345e+10   \n",
      "2            NaN           NaN  2.553198e+10  1.170124e+10  2.055475e+10   \n",
      "3            NaN           NaN  2.396398e+10  1.278057e+10  2.423176e+10   \n",
      "4            NaN           NaN  2.873278e+10  1.542289e+10  2.849863e+10   \n",
      "5            NaN           NaN  3.011118e+10  2.027261e+10  3.688448e+10   \n",
      "6            NaN           NaN  2.829585e+10  1.346725e+10  2.686502e+10   \n",
      "7            NaN           NaN  3.249085e+10  1.625687e+10  3.040347e+10   \n",
      "8            NaN  4.967267e+09  3.532892e+10  2.240927e+10  3.317529e+10   \n",
      "9            NaN  3.647724e+09  4.926114e+10  1.877182e+10  3.945899e+10   \n",
      "10           NaN  6.246461e+09  4.738676e+10  2.203113e+10  4.746203e+10   \n",
      "11           NaN  1.090046e+10  8.053757e+10  2.999823e+10  7.137446e+10   \n",
      "12  5.996698e+09  1.813183e+10  9.195777e+10  2.711255e+10  9.747180e+10   \n",
      "13  5.030691e+09  1.999485e+10  1.096651e+11  2.176672e+10  1.002997e+11   \n",
      "14  6.493907e+09  2.326048e+10  9.487008e+10  2.633910e+10  8.241593e+10   \n",
      "15  7.387107e+09  2.778869e+10  1.021835e+11  3.399055e+10  7.767515e+10   \n",
      "16  1.102384e+10  1.749272e+10  8.900619e+10  2.995502e+10  7.220970e+10   \n",
      "17  1.822449e+10  3.073919e+10  1.136948e+11  3.940129e+10  8.467316e+10   \n",
      "18  2.345584e+10  3.891680e+10  1.141603e+11  4.279321e+10  8.032009e+10   \n",
      "19  3.667095e+10  5.636227e+10  1.174480e+11  5.057943e+10  1.243910e+11   \n",
      "20  3.037771e+10  3.989635e+10  1.397408e+11  5.348048e+10  1.149051e+11   \n",
      "\n",
      "            RVTY            ES           DHI          ZBRA           KMI  \\\n",
      "0   8.435058e+08  6.094710e+09  2.183110e+09  1.307958e+09           NaN   \n",
      "1   1.788371e+09  8.388449e+09  5.503329e+09  2.272491e+09           NaN   \n",
      "2   2.392436e+09  8.105560e+09  7.779088e+09  2.890518e+09           NaN   \n",
      "3   2.540495e+09  8.769886e+09  9.288613e+09  2.200759e+09           NaN   \n",
      "4   2.428695e+09  1.296026e+10  7.021146e+09  1.786801e+09           NaN   \n",
      "5   2.873959e+09  1.479045e+10  3.607438e+09  1.782178e+09           NaN   \n",
      "6   1.553902e+09  1.173875e+10  1.989491e+09  1.040546e+09           NaN   \n",
      "7   2.340896e+09  1.312131e+10  3.106702e+09  1.456045e+09           NaN   \n",
      "8   2.973750e+09  1.682606e+10  3.454118e+09  1.951151e+09           NaN   \n",
      "9   2.330636e+09  1.965312e+10  3.701381e+09  1.837646e+09  3.982226e+10   \n",
      "10  3.739170e+09  2.206684e+10  5.904100e+09  2.018946e+09  4.546001e+10   \n",
      "11  4.896629e+09  2.480603e+10  6.662258e+09  2.777527e+09  4.827369e+10   \n",
      "12  5.227277e+09  3.240142e+10  7.616356e+09  3.975747e+09  5.946751e+10   \n",
      "13  6.440605e+09  3.198600e+10  9.738883e+09  3.577196e+09  2.214072e+10   \n",
      "14  6.304003e+09  3.574845e+10  8.407818e+09  4.404599e+09  3.160104e+10   \n",
      "15  8.879172e+09  4.217241e+10  1.589545e+10  5.331127e+09  2.826267e+10   \n",
      "16  9.572079e+09  4.487503e+10  1.092589e+10  8.177989e+09  2.510152e+10   \n",
      "17  1.187000e+10  6.035204e+10  1.685755e+10  1.311930e+10  3.625345e+10   \n",
      "18  1.759126e+10  6.303715e+10  2.229129e+10  1.973903e+10  2.510075e+10   \n",
      "19  2.469294e+10  6.819690e+10  3.538379e+10  3.056923e+10  3.106387e+10   \n",
      "20  1.725321e+10  6.474643e+10  2.942800e+10  1.316912e+10  3.766051e+10   \n",
      "\n",
      "            INVH           GPC          SWKS           GIS  \n",
      "0            NaN  2.239032e+09  1.176511e+09  7.150418e+09  \n",
      "1            NaN  2.506142e+09  1.187430e+09  7.064207e+09  \n",
      "2            NaN  3.430647e+09  1.287065e+09  7.952941e+09  \n",
      "3            NaN  3.518453e+09  6.947144e+08  8.048893e+09  \n",
      "4            NaN  3.918919e+09  9.663220e+08  9.653588e+09  \n",
      "5            NaN  3.941626e+09  1.160133e+09  9.807523e+09  \n",
      "6            NaN  3.349000e+09  7.561334e+08  1.073833e+10  \n",
      "7            NaN  3.523402e+09  1.936739e+09  1.291040e+10  \n",
      "8            NaN  4.951028e+09  3.907598e+09  1.336287e+10  \n",
      "9            NaN  6.102566e+09  2.213805e+09  1.566041e+10  \n",
      "10           NaN  6.545719e+09  2.770669e+09  1.617267e+10  \n",
      "11           NaN  8.807201e+09  3.898045e+09  2.058799e+10  \n",
      "12           NaN  1.157360e+10  9.992766e+09  2.270274e+10  \n",
      "13           NaN  9.589759e+09  1.065648e+10  2.532358e+10  \n",
      "14           NaN  1.096107e+10  1.052705e+10  2.793424e+10  \n",
      "15  1.249996e+10  1.122965e+10  1.354699e+10  2.775241e+10  \n",
      "16  1.086295e+10  1.169126e+10  9.712857e+09  1.899093e+10  \n",
      "17  1.654135e+10  1.333386e+10  1.788168e+10  2.718136e+10  \n",
      "18  1.673771e+10  1.304130e+10  2.295293e+10  3.087704e+10  \n",
      "19  2.604062e+10  1.869989e+10  2.357880e+10  3.659734e+10  \n",
      "20  1.743648e+10  2.371557e+10  1.415996e+10  4.687838e+10  \n",
      "Annual maket capital saved to stock_prices.xlsx\n"
     ]
    }
   ],
   "source": [
    "from Market_Cap import cal_market_cap, filter_last_date_per_year\n",
    "\n",
    "constituents_file = \"S&P 500 Constituent.xlsx\"\n",
    "constituents_data = pd.read_excel(\n",
    "    constituents_file, sheet_name=\"S&P 500 Constituent\")\n",
    "cal_market_cap(start_date, end_date, constituents_file, Output_file, tickers)\n",
    "\n",
    "\n",
    "sheet_name = 'Market_Caps'\n",
    "filtered_df = filter_last_date_per_year(Output_file, sheet_name)\n",
    "\n",
    "\n",
    "with pd.ExcelWriter(Output_file, engine='openpyxl', mode='a', if_sheet_exists=\"replace\") as writer:\n",
    "    filtered_df.to_excel(writer, sheet_name='Market_Caps')\n",
    "\n",
    "print(\"Annual maket capital saved to stock_prices.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating annual liquidity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculateing the sum of daily Volume for each firm per year, dividing it by the total shares outstanding, and saving it in the sheet “Liquidity_annual”. This is a measure of how frequently a stock is traded, and generally, it is perceived as a measure of its liquidity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CE: Data doesn't exist for startDate = 1009861200, endDate = 1041310800\n",
      "KEYS: Data doesn't exist for startDate = 1009861200, endDate = 1041310800\n",
      "NXPI: Data doesn't exist for startDate = 1009861200, endDate = 1041310800\n",
      "KMI: Data doesn't exist for startDate = 1009861200, endDate = 1041310800\n",
      "INVH: Data doesn't exist for startDate = 1009861200, endDate = 1041310800\n",
      "CE: Data doesn't exist for startDate = 1041397200, endDate = 1072846800\n",
      "KEYS: Data doesn't exist for startDate = 1041397200, endDate = 1072846800\n",
      "NXPI: Data doesn't exist for startDate = 1041397200, endDate = 1072846800\n",
      "KMI: Data doesn't exist for startDate = 1041397200, endDate = 1072846800\n",
      "INVH: Data doesn't exist for startDate = 1041397200, endDate = 1072846800\n",
      "CE: Data doesn't exist for startDate = 1072933200, endDate = 1104469200\n",
      "KEYS: Data doesn't exist for startDate = 1072933200, endDate = 1104469200\n",
      "NXPI: Data doesn't exist for startDate = 1072933200, endDate = 1104469200\n",
      "KMI: Data doesn't exist for startDate = 1072933200, endDate = 1104469200\n",
      "INVH: Data doesn't exist for startDate = 1072933200, endDate = 1104469200\n",
      "KEYS: Data doesn't exist for startDate = 1104555600, endDate = 1136005200\n",
      "NXPI: Data doesn't exist for startDate = 1104555600, endDate = 1136005200\n",
      "KMI: Data doesn't exist for startDate = 1104555600, endDate = 1136005200\n",
      "INVH: Data doesn't exist for startDate = 1104555600, endDate = 1136005200\n",
      "KEYS: Data doesn't exist for startDate = 1136091600, endDate = 1167541200\n",
      "NXPI: Data doesn't exist for startDate = 1136091600, endDate = 1167541200\n",
      "KMI: Data doesn't exist for startDate = 1136091600, endDate = 1167541200\n",
      "INVH: Data doesn't exist for startDate = 1136091600, endDate = 1167541200\n",
      "KEYS: Data doesn't exist for startDate = 1167627600, endDate = 1199077200\n",
      "NXPI: Data doesn't exist for startDate = 1167627600, endDate = 1199077200\n",
      "KMI: Data doesn't exist for startDate = 1167627600, endDate = 1199077200\n",
      "INVH: Data doesn't exist for startDate = 1167627600, endDate = 1199077200\n",
      "KEYS: Data doesn't exist for startDate = 1199163600, endDate = 1230699600\n",
      "NXPI: Data doesn't exist for startDate = 1199163600, endDate = 1230699600\n",
      "KMI: Data doesn't exist for startDate = 1199163600, endDate = 1230699600\n",
      "INVH: Data doesn't exist for startDate = 1199163600, endDate = 1230699600\n",
      "KEYS: Data doesn't exist for startDate = 1230786000, endDate = 1262235600\n",
      "NXPI: Data doesn't exist for startDate = 1230786000, endDate = 1262235600\n",
      "KMI: Data doesn't exist for startDate = 1230786000, endDate = 1262235600\n",
      "INVH: Data doesn't exist for startDate = 1230786000, endDate = 1262235600\n",
      "KEYS: Data doesn't exist for startDate = 1262322000, endDate = 1293771600\n",
      "KMI: Data doesn't exist for startDate = 1262322000, endDate = 1293771600\n",
      "INVH: Data doesn't exist for startDate = 1262322000, endDate = 1293771600\n",
      "KEYS: Data doesn't exist for startDate = 1293858000, endDate = 1325307600\n",
      "INVH: Data doesn't exist for startDate = 1293858000, endDate = 1325307600\n",
      "KEYS: Data doesn't exist for startDate = 1325394000, endDate = 1356930000\n",
      "INVH: Data doesn't exist for startDate = 1325394000, endDate = 1356930000\n",
      "KEYS: Data doesn't exist for startDate = 1357016400, endDate = 1388466000\n",
      "INVH: Data doesn't exist for startDate = 1357016400, endDate = 1388466000\n",
      "INVH: Data doesn't exist for startDate = 1388552400, endDate = 1420002000\n",
      "INVH: Data doesn't exist for startDate = 1420088400, endDate = 1451538000\n",
      "INVH: Data doesn't exist for startDate = 1451624400, endDate = 1483160400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liquidity data added to the Excel file.\n"
     ]
    }
   ],
   "source": [
    "from liquidity import cal_liquidity\n",
    "excel_file = \"Stock Data Output.xlsx\"  # Replace with your file path\n",
    "sheet_name = \"Liquidity_annual\"\n",
    "constituents_data = constituents_data[[\"ticker\", \"Name\", \"Share_outstanding\"]]\n",
    "cal_liquidity(Output_file, tickers, constituents_data, sheet_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating returns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using adjusted close prices at the annual, monthly, and daily frequencies, computing the annual, monthly, and daily returns. Saving them in new sheets labeled “Returns_annual”, “Returns_monthly”, and “Returns_daily”.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "def download_data(ticker, start_date, end_date):\n",
    "    benchmark_symbol = \"^GSPC\"\n",
    "    stock_data = yf.download(ticker, start=start_date, end=end_date)\n",
    "    benchmark_data = yf.download(benchmark_symbol, start=start_date, end=end_date)\n",
    "    return stock_data, benchmark_data\n",
    "\n",
    "\n",
    "for ticker in tickers:\n",
    "    data, benchmark_data = download_data(ticker, start_date, end_date)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data download, Excel file update, and returns calculation completed.\n"
     ]
    }
   ],
   "source": [
    "from returns import cal_returns\n",
    "\n",
    "cal_returns(Output_file, tickers, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating annual risks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using Returtns_daily, calculating the standard deviation of each stock in each year. Saving these in a new sheet called “Risk_annual”.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data download, Excel file update, returns calculation, and risk calculation completed.\n"
     ]
    }
   ],
   "source": [
    "from risk import cal_risks\n",
    "\n",
    "cal_risks(Output_file, tickers, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating statistics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calcuating summary statistics of our portfolio holdings (in sheet “Firm_Summary_Stat”)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from beta import cal_beta_main, calculate_beta\n",
    "\n",
    "# Load the data from Excel file\n",
    "returns_sheet_name = 'Returns_annual'\n",
    "constituents_sheet_name = 'S&P 500 Constituent'\n",
    "\n",
    "returns_data = pd.read_excel(\n",
    "    Output_file, sheet_name=returns_sheet_name, index_col=0)\n",
    "constituents_data = pd.read_excel(\n",
    "    \"S&P 500 Constituent.xlsx\", sheet_name=constituents_sheet_name, index_col=0)\n",
    "\n",
    "# Filter returns data for the last 5 years (2018:2022)\n",
    "returns_data_last_5_years = returns_data.loc['2018-01-01':'2022-12-31']\n",
    "\n",
    "# Create a new DataFrame for summary statistics\n",
    "summary_stats_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "# Calculate and add summary statistics for each firm\n",
    "summary_stats_df['Min'] = returns_data_last_5_years.min()\n",
    "summary_stats_df['Max'] = returns_data_last_5_years.max()\n",
    "summary_stats_df['Mean'] = returns_data_last_5_years.mean()\n",
    "summary_stats_df['Volatility'] = returns_data_last_5_years.std()\n",
    "\n",
    "# Load market capitalization data\n",
    "market_cap_data = pd.read_excel(\n",
    "    Output_file, sheet_name=\"Market_Caps\", index_col=0)\n",
    "\n",
    "# Add market capitalization (size) for each firm to the summary_stats_df\n",
    "# You can use mean() or any other aggregation method\n",
    "summary_stats_df['Size'] = market_cap_data.mean()\n",
    "\n",
    "\n",
    "# Add industry information for each firm\n",
    "summary_stats_df['Industry'] = constituents_data['GICS Sector']\n",
    "\n",
    "# Add a new sheet \"Firm_Summary_Stat\" to the existing Excel file\n",
    "with pd.ExcelWriter(Output_file, engine=\"openpyxl\", mode=\"a\", if_sheet_exists=\"replace\") as writer:\n",
    "    summary_stats_df.T.to_excel(\n",
    "        writer, sheet_name=\"Firm_Summary_Stat\", index=True, header=True)\n",
    "\n",
    "\n",
    "cal_beta_main(tickers,data,benchmark_data,start_date,end_date,constituents_file,Output_file,summary_stats_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Personal Portfolio Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Strategy = Return: Every January, invest more in firms that had a larger return last year. If they had negative returns, do not invest in them this year.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\Coding Projects\\Refined\\Financial Modelling-Yahoo Finance\\portfolio_analysis.py:26: FutureWarning: The argument 'date_parser' is deprecated and will be removed in a future version. Please use 'date_format' instead, or read your data in as 'object' dtype and then call 'to_datetime'.\n",
      "  FF_3Factor_All = pdr.get_data_famafrench('F-F_Research_Data_Factors', start_date, end_date)\n",
      "d:\\Projects\\Coding Projects\\Refined\\Financial Modelling-Yahoo Finance\\portfolio_analysis.py:26: FutureWarning: The argument 'date_parser' is deprecated and will be removed in a future version. Please use 'date_format' instead, or read your data in as 'object' dtype and then call 'to_datetime'.\n",
      "  FF_3Factor_All = pdr.get_data_famafrench('F-F_Research_Data_Factors', start_date, end_date)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['COR', 'CE', 'HUM', 'CINF', 'KEYS', 'NXPI', 'BMY', 'EMR', 'CVS', 'RVTY',\\n       'ES', 'DHI', 'ZBRA', 'KMI', 'INVH', 'GPC', 'SWKS', 'GIS'],\\n      dtype='object', name='Date')] are in the [index]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mportfolio_analysis\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cal_portfolio\n\u001b[1;32m----> 3\u001b[0m combined_returns, Rf \u001b[38;5;241m=\u001b[39m \u001b[43mcal_portfolio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtickers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbenchmark_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43mOutput_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Projects\\Coding Projects\\Refined\\Financial Modelling-Yahoo Finance\\portfolio_analysis.py:33\u001b[0m, in \u001b[0;36mcal_portfolio\u001b[1;34m(tickers, adj_price_data, benchmark, output_file_path)\u001b[0m\n\u001b[0;32m     30\u001b[0m Rf \u001b[38;5;241m=\u001b[39m FF_3Factor[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRF\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m     32\u001b[0m weights_0 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;28mlen\u001b[39m(tickers) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(tickers)\n\u001b[1;32m---> 33\u001b[0m optimal_weights \u001b[38;5;241m=\u001b[39m opt\u001b[38;5;241m.\u001b[39mfmin_bfgs(SharpeRatio, weights_0, args\u001b[38;5;241m=\u001b[39m(\u001b[43mReturns\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtickers\u001b[49m\u001b[43m]\u001b[49m, Rf))\n\u001b[0;32m     35\u001b[0m optimal_weights_all \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mappend(optimal_weights, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28msum\u001b[39m(optimal_weights))\n\u001b[0;32m     36\u001b[0m optimal_weights_all \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(optimal_weights_all, index\u001b[38;5;241m=\u001b[39mtickers)\n",
      "File \u001b[1;32mc:\\Users\\saif_\\miniconda3\\lib\\site-packages\\pandas\\core\\series.py:1033\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1030\u001b[0m     key \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(key, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[0;32m   1031\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_values(key)\n\u001b[1;32m-> 1033\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_with\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\saif_\\miniconda3\\lib\\site-packages\\pandas\\core\\series.py:1073\u001b[0m, in \u001b[0;36mSeries._get_with\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1070\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miloc[key]\n\u001b[0;32m   1072\u001b[0m \u001b[38;5;66;03m# handle the dup indexing case GH#4246\u001b[39;00m\n\u001b[1;32m-> 1073\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\saif_\\miniconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1103\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1100\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   1102\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m-> 1103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\saif_\\miniconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1332\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1329\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1330\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index with multidimensional key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1332\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_iterable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1334\u001b[0m \u001b[38;5;66;03m# nested tuple slicing\u001b[39;00m\n\u001b[0;32m   1335\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "File \u001b[1;32mc:\\Users\\saif_\\miniconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1272\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1269\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[0;32m   1271\u001b[0m \u001b[38;5;66;03m# A collection of keys\u001b[39;00m\n\u001b[1;32m-> 1272\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_listlike_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1273\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[0;32m   1274\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1275\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\saif_\\miniconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1462\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1459\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[0;32m   1460\u001b[0m axis_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis_name(axis)\n\u001b[1;32m-> 1462\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1464\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[1;32mc:\\Users\\saif_\\miniconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5876\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5873\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   5874\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 5876\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5878\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   5879\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   5880\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\saif_\\miniconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5935\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_interval_msg:\n\u001b[0;32m   5934\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 5935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   5937\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   5938\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['COR', 'CE', 'HUM', 'CINF', 'KEYS', 'NXPI', 'BMY', 'EMR', 'CVS', 'RVTY',\\n       'ES', 'DHI', 'ZBRA', 'KMI', 'INVH', 'GPC', 'SWKS', 'GIS'],\\n      dtype='object', name='Date')] are in the [index]\""
     ]
    }
   ],
   "source": [
    "from portfolio_analysis import cal_portfolio\n",
    "\n",
    "combined_returns, Rf = cal_portfolio(tickers, data, benchmark_data,Output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating portfolio performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from portfolio_perf import cal_portfolio_perf\n",
    "\n",
    "cal_portfolio_perf(combined_returns, Rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Portfolio Returns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from portfolio_return import cal_portfolio_return\n",
    "\n",
    "cal_portfolio_return(combined_returns, Rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating investment summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from invest_sum import cal_invest_sum\n",
    "\n",
    "cal_invest_sum(tickers, Rf, combined_returns, constituents_file, Output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making excel file more readalbe.\n",
    "\n",
    "###### (This is the last step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wraping Text\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
