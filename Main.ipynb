{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing initial libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from pandas_datareader import data as pdr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading and saving data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up yfinance to use pandas data reader\n",
    "yf.pdr_override()\n",
    "\n",
    "# Define the list of tickers\n",
    "tickers = ['COR', 'CE', 'HUM', 'CINF', 'KEYS', 'NXPI', 'BMY', 'EMR',\n",
    "           'CVS', 'RVTY', 'ES', 'DHI', 'ZBRA', 'KMI', 'INVH', 'GPC', 'SWKS', 'GIS']\n",
    "\n",
    "# Define the date range\n",
    "start_date = '2002-01-01'\n",
    "end_date = '2022-12-31'\n",
    "Output_file = 'stock_prices.xlsx'\n",
    "\n",
    "# Create a pandas DataFrame to store the data\n",
    "price_data = pdr.get_data_yahoo(\n",
    "    tickers, start=start_date, end=end_date)['Close']\n",
    "adj_price_data = pdr.get_data_yahoo(\n",
    "    tickers, start=start_date, end=end_date)['Adj Close']\n",
    "volume_data = pdr.get_data_yahoo(\n",
    "    tickers, start=start_date, end=end_date)['Volume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the datetime index to string in the format \"MM/DD/YYYY\"\n",
    "price_data.index = price_data.index.strftime('%m/%d/%Y')\n",
    "adj_price_data.index = adj_price_data.index.strftime('%m/%d/%Y')\n",
    "volume_data.index = volume_data.index.strftime('%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create an Excel writer\n",
    "with pd.ExcelWriter(Output_file, engine='openpyxl') as writer:\n",
    "    # Save close prices to \"Price_daily\" sheet\n",
    "    price_data.to_excel(writer, sheet_name='Price_daily')\n",
    "\n",
    "    # Save adjusted close prices to \"Adj_Price_daily\" sheet\n",
    "    adj_price_data.to_excel(writer, sheet_name='Adj_Price_daily')\n",
    "\n",
    "    # Save volume data to \"Volume_daily\" sheet\n",
    "    volume_data.to_excel(writer, sheet_name='Volume_daily')\n",
    "\n",
    "print(\"Stock prices saved to stock_prices.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_data = pdr.get_data_yahoo('^GSPC', start=start_date, end=end_date)[\n",
    "    [\"Adj Close\", \"Close\", \"High\", \"Low\", \"Open\", \"Volume\"]]\n",
    "sp500_data.index = sp500_data.index.strftime('%m/%d/%Y')\n",
    "\n",
    "with pd.ExcelWriter(Output_file, engine='openpyxl', mode='a', if_sheet_exists=\"replace\") as writer:\n",
    "    sp500_data.to_excel(writer, sheet_name='S&P 500')\n",
    "print(\"Prices for the S&P 500 index (^GSPC) saved to stock_prices.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Market Captilization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Market_Cap import cal_market_cap, filter_last_date_per_year\n",
    "\n",
    "constituents_file = \"S&P 500 Constituent.xlsx\"\n",
    "cal_market_cap(start_date, end_date, constituents_file, Output_file, tickers)\n",
    "\n",
    "\n",
    "sheet_name = 'Market_Caps'\n",
    "filtered_df = filter_last_date_per_year(Output_file, sheet_name)\n",
    "\n",
    "\n",
    "with pd.ExcelWriter(Output_file, engine='openpyxl', mode='a', if_sheet_exists=\"replace\") as writer:\n",
    "    filtered_df.to_excel(writer, sheet_name='Market_Caps')\n",
    "\n",
    "print(\"Annual maket capital saved to stock_prices.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating annual liquidity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from liquidity import cal_liquidity\n",
    "excel_file = \"Stock Data Output.xlsx\"  # Replace with your file path\n",
    "cal_liquidity(Output_file, tickers, constituents_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating returns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from returns import cal_returns\n",
    "\n",
    "cal_returns(Output_file, tickers, adj_price_data, start_date, end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Risks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_returns(prices):\n",
    "    return prices.pct_change()\n",
    "\n",
    "# Date range\n",
    "start_date = \"2002-01-01\"\n",
    "end_date = \"2022-12-31\"\n",
    "excel_file = \"Stock Data Output.xlsx\"\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Create a new Excel file or open existing file\n",
    "    with pd.ExcelWriter(excel_file, engine=\"openpyxl\", mode=\"a\", if_sheet_exists=\"replace\") as writer:\n",
    "        for data_type in [\"Adj_Price_daily\"]:\n",
    "            # Create an empty DataFrame to store combined data for all companies\n",
    "            combined_data = pd.DataFrame()\n",
    "\n",
    "            for ticker in company_names:\n",
    "                print(f\"Downloading {data_type} for {ticker}...\")\n",
    "                data = download_data(ticker, start_date, end_date)\n",
    "\n",
    "                # Extract relevant column for the current data type\n",
    "                if data_type == \"Adj_Price_daily\":\n",
    "                    current_data = data[\"Adj Close\"]\n",
    "\n",
    "                # Combine data for all tickers\n",
    "                combined_data[ticker] = current_data\n",
    "\n",
    "            # Write combined data to a single sheet\n",
    "            combined_data.to_excel(writer, sheet_name=data_type)\n",
    "\n",
    "            # Calculate returns\n",
    "            returns_daily = calculate_returns(combined_data)\n",
    "\n",
    "            # Append returns to existing or new sheets\n",
    "            returns_daily.to_excel(writer, sheet_name=\"Returns_daily\", index=True, header=True)\n",
    "\n",
    "            # Calculate and save standard deviation of each stock's returns for each year\n",
    "            risk_annual = returns_daily.groupby(returns_daily.index.year).std()\n",
    "            risk_annual.to_excel(writer, sheet_name=\"Risk_annual\", index=True, header=True)\n",
    "\n",
    "    print(\"Data download, Excel file update, returns calculation, and risk calculation completed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Volatility etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from Excel file\n",
    "file_path1 = 'Stock Data Output.xlsx'\n",
    "returns_sheet_name = 'Returns_annual'\n",
    "\n",
    "constituents_sheet_name = 'S&P 500 Constituent'\n",
    "\n",
    "returns_data = pd.read_excel(file_path1, sheet_name=returns_sheet_name, index_col=0)\n",
    "constituents_data = pd.read_excel(\"Company_Student_List .xlsx\", sheet_name=constituents_sheet_name, index_col=0)\n",
    "\n",
    "# Filter returns data for the last 5 years (2018:2022)\n",
    "returns_data_last_5_years = returns_data.loc['2018-01-01':'2022-12-31']\n",
    "\n",
    "# Create a new DataFrame for summary statistics\n",
    "summary_stats_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "# Calculate and add summary statistics for each firm\n",
    "summary_stats_df['Min'] = returns_data_last_5_years.min()\n",
    "summary_stats_df['Max'] = returns_data_last_5_years.max()\n",
    "summary_stats_df['Mean'] = returns_data_last_5_years.mean()\n",
    "summary_stats_df['Volatility'] = returns_data_last_5_years.std()\n",
    "\n",
    "# Load market capitalization data\n",
    "market_cap_data = pd.read_excel(file_path1, sheet_name=\"Market_Cap\", index_col=0)\n",
    "\n",
    "# Add market capitalization (size) for each firm to the summary_stats_df\n",
    "summary_stats_df['Size'] = market_cap_data.mean()  # You can use mean() or any other aggregation method\n",
    "\n",
    "\n",
    "\n",
    "# Add industry information for each firm\n",
    "summary_stats_df['Industry'] = constituents_data['GICS Sector']\n",
    "\n",
    "# Add a new sheet \"Firm_Summary_Stat\" to the existing Excel file\n",
    "with pd.ExcelWriter(file_path1, engine=\"openpyxl\", mode=\"a\", if_sheet_exists=\"replace\") as writer:\n",
    "    summary_stats_df.T.to_excel(writer, sheet_name=\"Firm_Summary_Stat\", index=True, header=True)\n",
    "\n",
    "\n",
    "def calculate_beta(stock_symbol, benchmark_symbol, start_date, end_date):\n",
    "    # Download historical stock prices\n",
    "    stock_data = yf.download(stock_symbol, start=start_date, end=end_date, interval='1mo')\n",
    "    benchmark_data = yf.download(benchmark_symbol, start=start_date, end=end_date, interval='1mo')\n",
    "\n",
    "    # Extract adjusted closing prices\n",
    "    stock_adj_close = stock_data['Adj Close']\n",
    "    benchmark_adj_close = benchmark_data['Adj Close']\n",
    "\n",
    "    # Calculate monthly returns\n",
    "    stock_returns = stock_adj_close.pct_change().dropna()\n",
    "    benchmark_returns = benchmark_adj_close.pct_change().dropna()\n",
    "\n",
    "    # Calculate covariance and variance\n",
    "    covariance = np.cov(stock_returns, benchmark_returns)[0, 1]\n",
    "    variance = np.var(benchmark_returns)\n",
    "\n",
    "    # Calculate beta\n",
    "    beta = covariance / variance\n",
    "\n",
    "    return beta\n",
    "\n",
    "ticker_list = company_names\n",
    "\n",
    "# Benchmark symbol (e.g., S&P 500)\n",
    "benchmark_symbol = \"^GSPC\"\n",
    "\n",
    "# Date range\n",
    "start_date = \"2018-01-01\"\n",
    "end_date = \"2022-01-01\"\n",
    "\n",
    "# Store beta values calculated from download in a dictionary\n",
    "downloaded_betas = {}\n",
    "for stock_symbol in ticker_list:\n",
    "    beta_value = calculate_beta(stock_symbol, benchmark_symbol, start_date, end_date)\n",
    "    downloaded_betas[stock_symbol] = beta_value\n",
    "\n",
    "# Replace 'your_tickers_list' with your list of tickers\n",
    "given_tickers = company_names\n",
    "\n",
    "\n",
    "# Replace 'Company_Student_List.xlsx' with the path to your Excel file\n",
    "excel_file_path = \"Company_Student_List .xlsx\"\n",
    "\n",
    "# Read the Excel file\n",
    "excel_data = pd.ExcelFile(excel_file_path)\n",
    "\n",
    "# Get the required sheet\n",
    "sheet_name = 'S&P 500 Constituent'\n",
    "sheet_data = excel_data.parse(sheet_name)\n",
    "\n",
    "# Get the column 'Market Beta on Nov 2023'\n",
    "market_beta_column = 'Market Beta on Nov 2023'\n",
    "\n",
    "# Filter rows based on the given tickers\n",
    "filtered_rows = sheet_data[sheet_data['ticker'].isin(given_tickers)]\n",
    "\n",
    "# Display the 'Ticker' and 'Market Beta on Nov 2023' columns for the filtered rows\n",
    "for index, row in filtered_rows.iterrows():\n",
    "    ticker = row['ticker']\n",
    "    excel_beta = row[market_beta_column]\n",
    "    \n",
    "    # Check if the ticker has a downloaded beta value\n",
    "    if ticker in downloaded_betas:\n",
    "        downloaded_beta = downloaded_betas[ticker]\n",
    "        \n",
    "        if (downloaded_beta>excel_beta):\n",
    "            percentage_difference = ((downloaded_beta - excel_beta) / max(abs(excel_beta), abs(downloaded_beta))) * 100\n",
    "        elif(excel_beta>downloaded_beta):\n",
    "            percentage_difference = ((excel_beta - downloaded_beta) / max(abs(excel_beta), abs(downloaded_beta))) * 100\n",
    "\n",
    "\n",
    "        # Calculate the difference in percentage\n",
    "\n",
    "\n",
    "        # Update the \"Firm_Summary_Stat\" sheet with Excel Beta, Downloaded Beta, and Percentage Difference\n",
    "        with pd.ExcelWriter(file_path1, engine=\"openpyxl\", mode=\"a\", if_sheet_exists=\"replace\") as writer:\n",
    "            summary_stats_df.at[ticker, 'Excel Beta'] = excel_beta\n",
    "            summary_stats_df.at[ticker, 'Downloaded Beta'] = downloaded_beta\n",
    "            summary_stats_df.at[ticker, 'Percentage Difference'] = percentage_difference\n",
    "            summary_stats_df.T.to_excel(writer, sheet_name=\"Firm_Summary_Stat\", index=True, header=True)\n",
    "        \n",
    "        # Print the results\n",
    "        #print(f\"Ticker: {ticker}, Downloaded Beta: {downloaded_beta}, Excel Beta: {excel_beta}, Difference (%): {percentage_difference}\")\n",
    "    else:\n",
    "        print(f\"Ticker: {ticker}, Downloaded Beta not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Personal Portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_datareader.data as pdr\n",
    "from pandas.tseries.offsets import MonthEnd\n",
    "import scipy.optimize as opt\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def SharpeRatio(weights, Ret, Rf):\n",
    "    w = np.append(weights, 1 - sum(weights))\n",
    "    Ret_portfolio = (w * Ret).sum(axis=1)\n",
    "    SR_portfolio = -1 * (Ret_portfolio.mean() - Rf) * 12 / Ret_portfolio.std() / np.sqrt(12)\n",
    "    return SR_portfolio\n",
    "\n",
    "# Code for the first part\n",
    "tickers = ['EMN', 'CINF', 'KEYS', 'CDW', 'RVTY', 'KMI', 'COR', 'NXPI', 'INVH', 'EMR', 'BMY', 'NCLH', 'GPC', 'HUM', 'DHI', 'ES', 'CVS', 'GIS', 'AEP', 'AXON', 'CE', 'ZBRA', 'SWKS', 'PEAK', 'SJM']\n",
    "start_date = '2003-01-01'\n",
    "end_date = '2022-12-31'\n",
    "panel_data = yf.download(tickers, start_date, end_date)\n",
    "\n",
    "# Resample data to monthly frequency and fill missing data with zeros\n",
    "Returns = panel_data['Adj Close'].resample(\"1m\").ffill().pct_change().fillna(0)\n",
    "\n",
    "FF_3Factor_All = pdr.get_data_famafrench('F-F_Research_Data_Factors', start_date, end_date)\n",
    "FF_3Factor = FF_3Factor_All[0] / 100\n",
    "FF_3Factor.index = FF_3Factor.index.to_timestamp() + MonthEnd(1)\n",
    "FF_3Factor = FF_3Factor[1:]\n",
    "Rf = FF_3Factor['RF'].mean()\n",
    "\n",
    "weights_0 = np.ones(len(tickers) - 1) / len(tickers)\n",
    "optimal_weights = opt.fmin_bfgs(SharpeRatio, weights_0, args=(Returns[tickers], Rf))\n",
    "\n",
    "optimal_weights_all = np.append(optimal_weights, 1 - sum(optimal_weights))\n",
    "optimal_weights_all = pd.Series(optimal_weights_all, index=tickers)\n",
    "optimal_SharpeRatio = -1 * SharpeRatio(optimal_weights, Returns[tickers], Rf)\n",
    "\n",
    "# Code for the second part\n",
    "# Define the ticker symbol for S&P 500 (^GSPC)\n",
    "ticker_symbol = \"^GSPC\"\n",
    "\n",
    "# Download historical data\n",
    "data_gspc = yf.download(ticker_symbol, start=start_date, end=end_date)\n",
    "\n",
    "# Resample data to get monthly returns\n",
    "monthly_returns_gspc = data_gspc['Adj Close'].resample('M').ffill().pct_change()\n",
    "\n",
    "# Combine Annesha's Fund and GSPC Monthly Return\n",
    "combined_returns = pd.DataFrame({\n",
    "    'Date': Returns.index.strftime('%Y-%m'),\n",
    "    \"Annesha's Fund\": (Returns[tickers] * optimal_weights_all).sum(axis=1).round(3),\n",
    "    'GSPC Monthly Return': monthly_returns_gspc.round(3),\n",
    "    'Year': Returns.index.year\n",
    "})\n",
    "\n",
    "# Reset the index before creating cumulative returns\n",
    "combined_returns.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Plot for annual returns as a bar chart\n",
    "annual_returns = combined_returns.groupby('Year').agg({'Annesha\\'s Fund': 'sum', 'GSPC Monthly Return': 'sum'})\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Bar chart for annual returns\n",
    "bar_width = 0.35\n",
    "plt.bar(annual_returns.index - bar_width/2, annual_returns[\"Annesha's Fund\"], bar_width, label=\"Annesha's Fund\")\n",
    "plt.bar(annual_returns.index + bar_width/2, annual_returns['GSPC Monthly Return'], bar_width, label='GSPC')\n",
    "\n",
    "plt.title('Annual Returns')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Returns')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Save the bar chart as an image\n",
    "bar_chart_image_path = 'bar_chart.png'\n",
    "plt.savefig(bar_chart_image_path)\n",
    "plt.close()\n",
    "\n",
    "# Create a cumulative returns DataFrame\n",
    "cumulative_returns = combined_returns.copy()\n",
    "cumulative_returns['Cumulative Annesha\\'s Fund'] = cumulative_returns[\"Annesha's Fund\"].cumsum()\n",
    "cumulative_returns['Cumulative GSPC'] = cumulative_returns['GSPC Monthly Return'].cumsum()\n",
    "\n",
    "# Plot for cumulative returns as a step plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Line chart for cumulative returns\n",
    "plt.step(cumulative_returns.index, cumulative_returns[\"Cumulative Annesha's Fund\"], label=\"Cumulative Annesha's Fund\", where='post')\n",
    "plt.step(cumulative_returns.index, cumulative_returns['Cumulative GSPC'], label='Cumulative GSPC', where='post')\n",
    "\n",
    "plt.title('Cumulative Returns')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Cumulative Returns')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Save the cumulative returns chart as an image\n",
    "cumulative_chart_image_path = 'cumulative_chart.png'\n",
    "plt.savefig(cumulative_chart_image_path)\n",
    "plt.close()\n",
    "\n",
    "# Save the output to an existing Excel file with the plots\n",
    "output_file_path = 'Stock Data Output.xlsx'\n",
    "with pd.ExcelWriter(output_file_path, engine='openpyxl', mode='a',if_sheet_exists=\"replace\") as writer:\n",
    "    # Save the combined returns to the sheet \"PortfolioReturn_monthly\"\n",
    "    combined_returns.to_excel(writer, index=False, sheet_name='PortfolioReturn_monthly')\n",
    "\n",
    "    # Save the bar chart image to the same worksheet\n",
    "    worksheet_bar_chart = writer.sheets['PortfolioReturn_monthly']\n",
    "    image_width = 400\n",
    "    image_height = 300\n",
    "    #worksheet_bar_chart.insert_image('F2', bar_chart_image_path, {'x_scale': image_width / 100, 'y_scale': image_height / 100})\n",
    "\n",
    "    # Save the cumulative returns chart image to the same worksheet\n",
    "    worksheet_cumulative_chart = writer.sheets['PortfolioReturn_monthly']\n",
    "    #worksheet_cumulative_chart.insert_image('M2', cumulative_chart_image_path, {'x_scale': image_width / 100, 'y_scale': image_height / 100})\n",
    "\n",
    "print(f'Output saved to {output_file_path}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating portfolio performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Calculate additional metrics\n",
    "portfolio_returns = combined_returns[\"Annesha's Fund\"]\n",
    "benchmark_returns = combined_returns['GSPC Monthly Return']\n",
    "\n",
    "portfolio_returns = portfolio_returns.fillna(0)\n",
    "benchmark_returns = benchmark_returns.fillna(0)\n",
    "\n",
    "# Check if there are NaN values after dropping them\n",
    "if portfolio_returns.isnull().any() or benchmark_returns.isnull().any():\n",
    "    raise ValueError(\"NaN values are present in portfolio or benchmark returns after dropping.\")\n",
    "\n",
    "# Calculate mean, std, min, max\n",
    "mean_return = portfolio_returns.mean()\n",
    "std_return = portfolio_returns.std()\n",
    "min_return = portfolio_returns.min()\n",
    "max_return = portfolio_returns.max()\n",
    "\n",
    "# Calculate Alpha, Beta, R-squared\n",
    "X = benchmark_returns.values.reshape(-1, 1)\n",
    "y = portfolio_returns.values\n",
    "\n",
    "# Check for NaN values in X and y\n",
    "if np.isnan(X).any() or np.isnan(y).any():\n",
    "    raise ValueError(\"NaN values are present in X or y after dropping.\")\n",
    "\n",
    "# Check if there are NaN values after dropping them\n",
    "if portfolio_returns.isnull().any() or benchmark_returns.isnull().any():\n",
    "    raise ValueError(\"NaN values are present in portfolio or benchmark returns after dropping.\")\n",
    "\n",
    "model = LinearRegression().fit(X, y)\n",
    "alpha = model.intercept_\n",
    "beta = model.coef_[0]\n",
    "r_squared = model.score(X, y)\n",
    "\n",
    "# Check if there are NaN values in the calculated metrics\n",
    "if np.isnan(alpha) or np.isnan(beta) or np.isnan(r_squared):\n",
    "    raise ValueError(\"NaN values are present in calculated metrics.\")\n",
    "\n",
    "# Calculate Sharpe ratio\n",
    "sharpe_ratio = (mean_return - Rf) / std_return\n",
    "\n",
    "# Calculate Treynor ratio\n",
    "treynor_ratio = (mean_return - Rf) / beta\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Mean Return: {mean_return:.4f}\")\n",
    "print(f\"Standard Deviation (in %): {std_return * 100:.4f}\")\n",
    "print(f\"Minimum Return (in %): {min_return * 100:.4f}\")\n",
    "print(f\"Maximum Return (in %): {max_return * 100:.4f}\")\n",
    "print(f\"Alpha: {alpha:.4f}\")\n",
    "print(f\"Beta: {beta:.4f}\")\n",
    "print(f\"R-squared: {r_squared:.4f}\")\n",
    "print(f\"Sharpe Ratio: {sharpe_ratio:.4f}\")\n",
    "print(f\"Treynor Ratio: {treynor_ratio:.4f}\")\n",
    "\n",
    "# Plot a histogram of portfolio returns with lines for Annesha Fund and GSPC\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot histogram\n",
    "hist, bins, _ = plt.hist(portfolio_returns, bins=20, color='white', edgecolor='maroon', alpha=0.7,histtype='step', label=\"Annesha's Fund\", density=True)\n",
    "plt.hist(benchmark_returns, bins=bins, color='white', edgecolor='blue', alpha=0.7, label='GSPC', density=True,histtype='step')\n",
    "\n",
    "plt.title('Histogram of Portfolio Returns')\n",
    "plt.xlabel('Monthly Returns')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.grid(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Portfolio Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Calculate additional metrics\n",
    "portfolio_returns = combined_returns[\"Annesha's Fund\"]\n",
    "benchmark_returns = combined_returns['GSPC Monthly Return']\n",
    "\n",
    "portfolio_returns = portfolio_returns.fillna(0)\n",
    "benchmark_returns = benchmark_returns.fillna(0)\n",
    "\n",
    "# Check if there are NaN values after dropping them\n",
    "if portfolio_returns.isnull().any() or benchmark_returns.isnull().any():\n",
    "    raise ValueError(\"NaN values are present in portfolio or benchmark returns after dropping.\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Calculate additional metrics\n",
    "portfolio_returns = combined_returns[\"Annesha's Fund\"]\n",
    "benchmark_returns = combined_returns['GSPC Monthly Return']\n",
    "\n",
    "portfolio_returns = portfolio_returns.fillna(0)\n",
    "benchmark_returns = benchmark_returns.fillna(0)\n",
    "\n",
    "# Check if there are NaN values after dropping them\n",
    "if portfolio_returns.isnull().any() or benchmark_returns.isnull().any():\n",
    "    raise ValueError(\"NaN values are present in portfolio or benchmark returns after dropping.\")\n",
    "\n",
    "# Calculate mean, std, min, max in annual percentage rates\n",
    "mean_return_annual = (1 + portfolio_returns).prod() ** (12 / len(portfolio_returns.index)) - 1\n",
    "std_return_annual = portfolio_returns.std() * np.sqrt(12)\n",
    "min_return_annual = portfolio_returns.min() * 12\n",
    "max_return_annual = portfolio_returns.max() * 12\n",
    "\n",
    "# Convert to percentage for display\n",
    "mean_return_annual_percent = mean_return_annual * 100\n",
    "std_return_annual_percent = std_return_annual * 100\n",
    "min_return_annual_percent = min_return_annual * 100\n",
    "max_return_annual_percent = max_return_annual * 100\n",
    "\n",
    "# Calculate Alpha, Beta, R-squared for Annesha Fund\n",
    "X_portfolio = benchmark_returns.values.reshape(-1, 1)\n",
    "y_portfolio = portfolio_returns.values\n",
    "\n",
    "# Check for NaN values in X and y\n",
    "if np.isnan(X_portfolio).any() or np.isnan(y_portfolio).any():\n",
    "    raise ValueError(\"NaN values are present in X or y for Annesha Fund after dropping.\")\n",
    "\n",
    "# Check if there are NaN values after dropping them\n",
    "if portfolio_returns.isnull().any() or benchmark_returns.isnull().any():\n",
    "    raise ValueError(\"NaN values are present in Annesha Fund or benchmark returns after dropping.\")\n",
    "\n",
    "model_portfolio = LinearRegression().fit(X_portfolio, y_portfolio)\n",
    "alpha_portfolio = model_portfolio.intercept_\n",
    "beta_portfolio = model_portfolio.coef_[0]\n",
    "r_squared_portfolio = model_portfolio.score(X_portfolio, y_portfolio)\n",
    "\n",
    "# Calculate Sharpe ratio and Treynor ratio for Annesha Fund\n",
    "sharpe_ratio_portfolio = (mean_return_annual - Rf) / std_return_annual\n",
    "treynor_ratio_portfolio = (mean_return_annual - Rf) / beta_portfolio\n",
    "\n",
    "# Calculate Alpha, Beta, R-squared for GSPC\n",
    "X_gspc = benchmark_returns.values.reshape(-1, 1)\n",
    "y_gspc = benchmark_returns.values\n",
    "\n",
    "# Check for NaN values in X and y\n",
    "if np.isnan(X_gspc).any() or np.isnan(y_gspc).any():\n",
    "    raise ValueError(\"NaN values are present in X or y for GSPC after dropping.\")\n",
    "\n",
    "model_gspc = LinearRegression().fit(X_gspc, y_gspc)\n",
    "alpha_gspc = model_gspc.intercept_\n",
    "beta_gspc = model_gspc.coef_[0]\n",
    "r_squared_gspc = model_gspc.score(X_gspc, y_gspc)\n",
    "\n",
    "# Calculate Sharpe ratio and Treynor ratio for GSPC\n",
    "sharpe_ratio_gspc = (benchmark_returns.mean() * 12 - Rf) / (benchmark_returns.std() * np.sqrt(12))\n",
    "treynor_ratio_gspc = (benchmark_returns.mean() * 12 - Rf) / beta_gspc\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "summary_data = pd.DataFrame({\n",
    "    'Variable': ['Average', 'Standard Deviation', 'Minimum', 'Maximum', 'Alpha', 'Beta', 'R-squared', 'Sharpe Ratio', 'Treynor Ratio'],\n",
    "    \"Annesha Fund\": [f'{mean_return_annual_percent:.2f}%', f'{std_return_annual_percent:.2f}%', f'{min_return_annual_percent:.2f}%', f'{max_return_annual_percent:.2f}%', alpha_portfolio, beta_portfolio, r_squared_portfolio, sharpe_ratio_portfolio, treynor_ratio_portfolio],\n",
    "    'GSPC': [f'{benchmark_returns.mean() * 12 * 100:.2f}%', f'{benchmark_returns.std() * np.sqrt(12) * 100:.2f}%', f'{benchmark_returns.min() * 12 * 100:.2f}%', f'{benchmark_returns.max() * 12 * 100:.2f}%', alpha_gspc, beta_gspc, r_squared_gspc, sharpe_ratio_gspc, treynor_ratio_gspc]\n",
    "})\n",
    "\n",
    "# Save the summary data to Excel\n",
    "excel_file_path = 'Stock Data Output.xlsx'\n",
    "with pd.ExcelWriter(excel_file_path, engine=\"openpyxl\", mode=\"a\", if_sheet_exists=\"replace\") as writer:\n",
    "    summary_data.to_excel(writer, sheet_name='Fund_summary', index=False)\n",
    "\n",
    "# Plot a histogram of portfolio returns with lines for Annesha Fund and GSPC\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot histogram\n",
    "hist, bins, _ = plt.hist(portfolio_returns, bins=20, color='white', edgecolor='maroon', alpha=0.7, histtype='step', label=\"Annesha Fund\", density=True)\n",
    "plt.hist(benchmark_returns, bins=bins, color='white', edgecolor='blue', alpha=0.7, label='GSPC', density=True, histtype='step')\n",
    "\n",
    "plt.title('Histogram of Portfolio Returns')\n",
    "plt.xlabel('Monthly Returns')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.grid(False)\n",
    "plt.savefig('Histogram_Portfolio_Returns.png')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating investment summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf\n",
    "import scipy.optimize as opt\n",
    "from pandas.tseries.offsets import MonthEnd\n",
    "\n",
    "# Function to calculate Sharpe Ratio\n",
    "def SharpeRatio(weights, Ret, Rf):\n",
    "    w = np.append(weights, 1 - sum(weights))\n",
    "    Ret_portfolio = (w * Ret).sum(axis=1)\n",
    "    SR_portfolio = -1 * (Ret_portfolio.mean() - Rf) * 12 / Ret_portfolio.std() / np.sqrt(12)\n",
    "    return SR_portfolio\n",
    "\n",
    "# Define the tickers and other parameters\n",
    "tickers = ['EMN', 'CINF', 'KEYS', 'CDW', 'RVTY', 'KMI', 'COR', 'NXPI', 'INVH', 'EMR', 'BMY', 'NCLH', 'GPC', 'HUM', 'DHI', 'ES', 'CVS', 'GIS', 'AEP', 'AXON', 'CE', 'ZBRA', 'SWKS', 'PEAK', 'SJM']\n",
    "start_date = '2003-01-01'\n",
    "end_date = '2023-11-30'  # Updated end date\n",
    "\n",
    "# Download data\n",
    "panel_data = yf.download(tickers, start_date, end_date)\n",
    "\n",
    "# Resample data to monthly frequency and fill missing data with zeros\n",
    "Returns = panel_data['Adj Close'].resample(\"1m\").ffill().pct_change().fillna(0)\n",
    "\n",
    "# Set initial weights\n",
    "weights_0 = np.ones(len(tickers) - 1) / len(tickers)\n",
    "\n",
    "# Optimize weights to maximize Sharpe Ratio\n",
    "optimal_weights = opt.fmin_bfgs(SharpeRatio, weights_0, args=(Returns[tickers], Rf))\n",
    "\n",
    "# Calculate final weights with cash\n",
    "optimal_weights_all = np.append(optimal_weights, 1 - sum(optimal_weights))\n",
    "optimal_weights_all = pd.Series(optimal_weights_all, index=tickers)\n",
    "\n",
    "# Calculate investments in each firm at the end of the sample\n",
    "investments = panel_data['Adj Close'].iloc[-1] * optimal_weights_all\n",
    "\n",
    "# Ensure that investments are non-negative\n",
    "investments[investments < 0] = 0\n",
    "\n",
    "# Calculate percentage investments\n",
    "percentage_investments = (investments / investments.sum()) * 100\n",
    "\n",
    "# Preserve the original order of tickers\n",
    "percentage_investments = percentage_investments.loc[tickers]\n",
    "\n",
    "# Display investments\n",
    "print(\"Investments at the end of the sample:\")\n",
    "print(percentage_investments.round(2))\n",
    "\n",
    "# Save the summary data to Excel\n",
    "excel_file_path = 'Company_Student_List .xlsx'\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "summary_data = pd.DataFrame({'Symbols': tickers, end_date: percentage_investments.round(2)})\n",
    "# Append the summary_data to the 'fund_summary2' sheet in the Excel file\n",
    "with pd.ExcelWriter(\"Stock Data Output.xlsx\", engine=\"openpyxl\", mode=\"a\", if_sheet_exists=\"replace\") as writer:\n",
    "    summary_data.to_excel(writer, sheet_name='fund_summary2', index=False)\n",
    "\n",
    "# Load industry data from Excel\n",
    "industry_data = pd.read_excel(excel_file_path, sheet_name='S&P 500 Constituent', usecols=['ticker', 'GICS Sector'])\n",
    "\n",
    "# Merge industry data with summary_data\n",
    "summary_data = pd.merge(summary_data, industry_data, left_on='Symbols', right_on='ticker', how='left')\n",
    "\n",
    "# Group by industry and sum investments\n",
    "industry_investments = summary_data.groupby('GICS Sector')[end_date].sum()\n",
    "\n",
    "# Plot a pie chart with leader lines for industries\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "wedges, texts, autotexts = ax.pie(industry_investments, autopct='%1.1f%%', textprops=dict(color=\"w\"))\n",
    "\n",
    "# Add leader lines\n",
    "for i, text in enumerate(texts):\n",
    "    angle = (wedges[i].theta2 - wedges[i].theta1) / 2. + wedges[i].theta1\n",
    "    x = np.cos(np.radians(angle))\n",
    "    y = np.sin(np.radians(angle))\n",
    "    horizontalalignment = {-1: \"right\", 1: \"left\"}[int(np.sign(x))]\n",
    "    connectionstyle = f\"angle,angleA=0,angleB={angle}\"\n",
    "    ax.annotate(f'{industry_investments.index[i]}', xy=(x, y), xytext=(1.35 * np.sign(x), 1.4 * y),\n",
    "                horizontalalignment=horizontalalignment, arrowprops=dict(arrowstyle=\"->\", connectionstyle=\"arc3\", color='black'))\n",
    "\n",
    "plt.title('Industry Composition at the End of the Sample')\n",
    "plt.savefig('industry_pie_chart.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making excel file more readalbe.\n",
    "\n",
    "###### (This is the last step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wraping Text\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
