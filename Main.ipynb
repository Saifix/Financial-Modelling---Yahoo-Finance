{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing initial libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from pandas_datareader import data as pdr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading and saving data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  18 of 18 completed\n",
      "[*********************100%%**********************]  18 of 18 completed\n",
      "[*********************100%%**********************]  18 of 18 completed\n"
     ]
    }
   ],
   "source": [
    "# Set up yfinance to use pandas data reader\n",
    "yf.pdr_override()\n",
    "\n",
    "# Define the list of tickers\n",
    "tickers = ['COR', 'CE', 'HUM', 'CINF', 'KEYS', 'NXPI', 'BMY', 'EMR',\n",
    "           'CVS', 'RVTY', 'ES', 'DHI', 'ZBRA', 'KMI', 'INVH', 'GPC', 'SWKS', 'GIS']\n",
    "\n",
    "# Define the date range\n",
    "start_date = '2002-01-01'\n",
    "end_date = '2022-12-31'\n",
    "Output_file = 'stock_prices.xlsx'\n",
    "\n",
    "# Create a pandas DataFrame to store the data\n",
    "price_data = pdr.get_data_yahoo(\n",
    "    tickers, start=start_date, end=end_date)['Close']\n",
    "adj_price_data = pdr.get_data_yahoo(\n",
    "    tickers, start=start_date, end=end_date)['Adj Close']\n",
    "volume_data = pdr.get_data_yahoo(\n",
    "    tickers, start=start_date, end=end_date)['Volume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the datetime index to string in the format \"MM/DD/YYYY\"\n",
    "price_data.index = price_data.index.strftime('%m/%d/%Y')\n",
    "adj_price_data.index = adj_price_data.index.strftime('%m/%d/%Y')\n",
    "volume_data.index = volume_data.index.strftime('%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock prices saved to stock_prices.xlsx\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create an Excel writer\n",
    "with pd.ExcelWriter(Output_file, engine='openpyxl') as writer:\n",
    "    # Save close prices to \"Price_daily\" sheet\n",
    "    price_data.to_excel(writer, sheet_name='Price_daily')\n",
    "\n",
    "    # Save adjusted close prices to \"Adj_Price_daily\" sheet\n",
    "    adj_price_data.to_excel(writer, sheet_name='Adj_Price_daily')\n",
    "\n",
    "    # Save volume data to \"Volume_daily\" sheet\n",
    "    volume_data.to_excel(writer, sheet_name='Volume_daily')\n",
    "\n",
    "print(\"Stock prices saved to stock_prices.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "Prices for the S&P 500 index (^GSPC) saved to stock_prices.xlsx\n"
     ]
    }
   ],
   "source": [
    "sp500_data = pdr.get_data_yahoo('^GSPC', start=start_date, end=end_date)[\n",
    "    [\"Adj Close\", \"Close\", \"High\", \"Low\", \"Open\", \"Volume\"]]\n",
    "sp500_data.index = sp500_data.index.strftime('%m/%d/%Y')\n",
    "\n",
    "with pd.ExcelWriter(Output_file, engine='openpyxl', mode='a', if_sheet_exists=\"replace\") as writer:\n",
    "    sp500_data.to_excel(writer, sheet_name='S&P 500')\n",
    "print(\"Prices for the S&P 500 index (^GSPC) saved to stock_prices.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Market Captilization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Market capitalization data added to the Excel file.\n",
      "          Date           COR            CE           HUM          CINF  \\\n",
      "0   2002-12-31  2.095853e+09           NaN  1.107812e+09  2.546110e+09   \n",
      "1   2003-12-31  2.216051e+09           NaN  2.531349e+09  2.904205e+09   \n",
      "2   2004-12-31  2.272264e+09           NaN  3.289090e+09  3.317502e+09   \n",
      "3   2005-12-30  3.211910e+09  1.605232e+09  6.018737e+09  3.619249e+09   \n",
      "4   2006-12-29  3.497821e+09  2.190745e+09  6.127302e+09  3.778134e+09   \n",
      "5   2007-12-31  3.614503e+09  3.599710e+09  8.342923e+09  3.408419e+09   \n",
      "6   2008-12-31  2.897553e+09  1.062671e+09  4.129919e+09  2.632865e+09   \n",
      "7   2009-12-31  4.286258e+09  2.768339e+09  4.862183e+09  2.538391e+09   \n",
      "8   2010-12-31  5.674673e+09  3.571044e+09  6.064159e+09  3.235817e+09   \n",
      "9   2011-12-30  6.259214e+09  3.858796e+09  9.793614e+09  3.284150e+09   \n",
      "10  2012-12-31  7.382483e+09  3.906720e+09  7.777370e+09  4.408009e+09   \n",
      "11  2013-12-31  1.220708e+10  4.902934e+09  1.184524e+10  6.104032e+09   \n",
      "12  2014-12-31  1.586359e+10  5.402106e+09  1.662551e+10  6.264233e+09   \n",
      "13  2015-12-31  1.846303e+10  6.174732e+09  2.079345e+10  7.456092e+09   \n",
      "14  2016-12-30  1.415702e+10  7.373792e+09  2.388171e+10  9.807515e+09   \n",
      "15  2017-12-29  1.691945e+10  1.021392e+10  2.927993e+10  1.003695e+10   \n",
      "16  2018-12-31  1.394677e+10  8.752726e+09  3.404445e+10  1.066469e+10   \n",
      "17  2019-12-31  1.624530e+10  1.224085e+10  4.389574e+10  1.481030e+10   \n",
      "18  2020-12-31  1.901238e+10  1.325104e+10  4.947423e+10  1.271538e+10   \n",
      "19  2021-12-31  2.623972e+10  1.745802e+10  5.630080e+10  1.694655e+10   \n",
      "20  2022-12-30  3.313085e+10  1.086346e+10  6.258040e+10  1.560942e+10   \n",
      "\n",
      "            KEYS          NXPI           BMY           EMR           CVS  \\\n",
      "0            NaN           NaN  2.131470e+10  8.020549e+09  1.121660e+10   \n",
      "1            NaN           NaN  2.752512e+10  1.053251e+10  1.636345e+10   \n",
      "2            NaN           NaN  2.553198e+10  1.170124e+10  2.055475e+10   \n",
      "3            NaN           NaN  2.396399e+10  1.278058e+10  2.423176e+10   \n",
      "4            NaN           NaN  2.873279e+10  1.542290e+10  2.849863e+10   \n",
      "5            NaN           NaN  3.011117e+10  2.027261e+10  3.688449e+10   \n",
      "6            NaN           NaN  2.829587e+10  1.346724e+10  2.686501e+10   \n",
      "7            NaN           NaN  3.249086e+10  1.625686e+10  3.040347e+10   \n",
      "8            NaN  4.967266e+09  3.532893e+10  2.240927e+10  3.317528e+10   \n",
      "9            NaN  3.647724e+09  4.926115e+10  1.877182e+10  3.945898e+10   \n",
      "10           NaN  6.246462e+09  4.738677e+10  2.203113e+10  4.746204e+10   \n",
      "11           NaN  1.090046e+10  8.053759e+10  2.999824e+10  7.137446e+10   \n",
      "12  5.996698e+09  1.813183e+10  9.195776e+10  2.711255e+10  9.747183e+10   \n",
      "13  5.030691e+09  1.999485e+10  1.096651e+11  2.176672e+10  1.002997e+11   \n",
      "14  6.493907e+09  2.326048e+10  9.487006e+10  2.633910e+10  8.241594e+10   \n",
      "15  7.387107e+09  2.778869e+10  1.021835e+11  3.399056e+10  7.767515e+10   \n",
      "16  1.102384e+10  1.749272e+10  8.900621e+10  2.995501e+10  7.220969e+10   \n",
      "17  1.822449e+10  3.073919e+10  1.136948e+11  3.940131e+10  8.467317e+10   \n",
      "18  2.345584e+10  3.891680e+10  1.141603e+11  4.279321e+10  8.032011e+10   \n",
      "19  3.667095e+10  5.636227e+10  1.174480e+11  5.057944e+10  1.243911e+11   \n",
      "20  3.037771e+10  3.989635e+10  1.397408e+11  5.348048e+10  1.149051e+11   \n",
      "\n",
      "            RVTY            ES           DHI          ZBRA           KMI  \\\n",
      "0   8.435056e+08  6.094707e+09  2.183110e+09  1.307958e+09           NaN   \n",
      "1   1.788370e+09  8.388452e+09  5.503330e+09  2.272491e+09           NaN   \n",
      "2   2.392435e+09  8.105562e+09  7.779088e+09  2.890518e+09           NaN   \n",
      "3   2.540493e+09  8.769888e+09  9.288610e+09  2.200759e+09           NaN   \n",
      "4   2.428695e+09  1.296026e+10  7.021145e+09  1.786801e+09           NaN   \n",
      "5   2.873959e+09  1.479045e+10  3.607439e+09  1.782178e+09           NaN   \n",
      "6   1.553901e+09  1.173875e+10  1.989491e+09  1.040546e+09           NaN   \n",
      "7   2.340897e+09  1.312131e+10  3.106704e+09  1.456045e+09           NaN   \n",
      "8   2.973751e+09  1.682606e+10  3.454117e+09  1.951151e+09           NaN   \n",
      "9   2.330636e+09  1.965312e+10  3.701381e+09  1.837646e+09  3.982225e+10   \n",
      "10  3.739170e+09  2.206684e+10  5.904097e+09  2.018946e+09  4.546001e+10   \n",
      "11  4.896628e+09  2.480602e+10  6.662257e+09  2.777527e+09  4.827369e+10   \n",
      "12  5.227276e+09  3.240141e+10  7.616355e+09  3.975747e+09  5.946751e+10   \n",
      "13  6.440605e+09  3.198599e+10  9.738881e+09  3.577196e+09  2.214071e+10   \n",
      "14  6.304004e+09  3.574845e+10  8.407816e+09  4.404599e+09  3.160103e+10   \n",
      "15  8.879170e+09  4.217240e+10  1.589545e+10  5.331127e+09  2.826268e+10   \n",
      "16  9.572074e+09  4.487503e+10  1.092589e+10  8.177989e+09  2.510152e+10   \n",
      "17  1.187001e+10  6.035204e+10  1.685755e+10  1.311930e+10  3.625343e+10   \n",
      "18  1.759126e+10  6.303715e+10  2.229130e+10  1.973903e+10  2.510075e+10   \n",
      "19  2.469295e+10  6.819691e+10  3.538379e+10  3.056923e+10  3.106388e+10   \n",
      "20  1.725321e+10  6.474644e+10  2.942800e+10  1.316912e+10  3.766051e+10   \n",
      "\n",
      "            INVH           GPC          SWKS           GIS  \n",
      "0            NaN  2.239032e+09  1.176511e+09  7.150421e+09  \n",
      "1            NaN  2.506143e+09  1.187430e+09  7.064207e+09  \n",
      "2            NaN  3.430647e+09  1.287065e+09  7.952943e+09  \n",
      "3            NaN  3.518453e+09  6.947147e+08  8.048893e+09  \n",
      "4            NaN  3.918921e+09  9.663222e+08  9.653588e+09  \n",
      "5            NaN  3.941626e+09  1.160133e+09  9.807524e+09  \n",
      "6            NaN  3.349000e+09  7.561333e+08  1.073833e+10  \n",
      "7            NaN  3.523403e+09  1.936738e+09  1.291040e+10  \n",
      "8            NaN  4.951027e+09  3.907599e+09  1.336287e+10  \n",
      "9            NaN  6.102566e+09  2.213806e+09  1.566041e+10  \n",
      "10           NaN  6.545718e+09  2.770670e+09  1.617267e+10  \n",
      "11           NaN  8.807199e+09  3.898045e+09  2.058800e+10  \n",
      "12           NaN  1.157360e+10  9.992766e+09  2.270274e+10  \n",
      "13           NaN  9.589763e+09  1.065649e+10  2.532358e+10  \n",
      "14           NaN  1.096107e+10  1.052705e+10  2.793424e+10  \n",
      "15  1.249996e+10  1.122965e+10  1.354699e+10  2.775241e+10  \n",
      "16  1.086295e+10  1.169126e+10  9.712856e+09  1.899093e+10  \n",
      "17  1.654135e+10  1.333386e+10  1.788168e+10  2.718136e+10  \n",
      "18  1.673771e+10  1.304130e+10  2.295292e+10  3.087705e+10  \n",
      "19  2.604061e+10  1.869989e+10  2.357880e+10  3.659734e+10  \n",
      "20  1.743648e+10  2.371557e+10  1.415996e+10  4.687839e+10  \n",
      "Annual maket capital saved to stock_prices.xlsx\n"
     ]
    }
   ],
   "source": [
    "from Market_Cap import cal_market_cap, filter_last_date_per_year\n",
    "\n",
    "constituents_file = \"S&P 500 Constituent.xlsx\"\n",
    "cal_market_cap(start_date, end_date, constituents_file, Output_file, tickers)\n",
    "\n",
    "\n",
    "sheet_name = 'Market_Caps'\n",
    "filtered_df = filter_last_date_per_year(Output_file, sheet_name)\n",
    "\n",
    "\n",
    "with pd.ExcelWriter(Output_file, engine='openpyxl', mode='a', if_sheet_exists=\"replace\") as writer:\n",
    "    filtered_df.to_excel(writer, sheet_name='Market_Caps')\n",
    "\n",
    "print(\"Annual maket capital saved to stock_prices.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating annual liquidity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculateing the sum of daily Volume for each firm per year, dividing it by the total shares outstanding, and saving it in the sheet “Liquidity_annual”. This is a measure of how frequently a stock is traded, and generally, it is perceived as a measure of its liquidity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed download for COR: 'str' object has no attribute 'loc'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CE: Data doesn't exist for startDate = 1009861200, endDate = 1041310800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed download for CE: 'str' object has no attribute 'loc'\n",
      "Failed download for HUM: 'str' object has no attribute 'loc'\n",
      "Failed download for CINF: 'str' object has no attribute 'loc'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KEYS: Data doesn't exist for startDate = 1009861200, endDate = 1041310800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed download for KEYS: 'str' object has no attribute 'loc'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NXPI: Data doesn't exist for startDate = 1009861200, endDate = 1041310800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed download for NXPI: 'str' object has no attribute 'loc'\n",
      "Failed download for BMY: 'str' object has no attribute 'loc'\n",
      "Failed download for EMR: 'str' object has no attribute 'loc'\n",
      "Failed download for CVS: 'str' object has no attribute 'loc'\n",
      "Failed download for RVTY: 'str' object has no attribute 'loc'\n",
      "Failed download for ES: 'str' object has no attribute 'loc'\n",
      "Failed download for DHI: 'str' object has no attribute 'loc'\n",
      "Failed download for ZBRA: 'str' object has no attribute 'loc'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KMI: Data doesn't exist for startDate = 1009861200, endDate = 1041310800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed download for KMI: 'str' object has no attribute 'loc'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INVH: Data doesn't exist for startDate = 1009861200, endDate = 1041310800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed download for INVH: 'str' object has no attribute 'loc'\n",
      "Failed download for GPC: 'str' object has no attribute 'loc'\n",
      "Failed download for SWKS: 'str' object has no attribute 'loc'\n",
      "Failed download for GIS: 'str' object has no attribute 'loc'\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Year'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 36\u001b[0m\n\u001b[0;32m     33\u001b[0m liquidity_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(liquidity_data)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Pivot the DataFrame to have years in the first column and tickers in the header row\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m pivot_liquidity_df \u001b[38;5;241m=\u001b[39m \u001b[43mliquidity_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpivot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mYear\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTicker\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLiquidity\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Save the pivoted liquidity data for the year in a new sheet\u001b[39;00m\n\u001b[0;32m     39\u001b[0m pivot_liquidity_df\u001b[38;5;241m.\u001b[39mto_excel(writer, sheet_name\u001b[38;5;241m=\u001b[39msheet_name, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\saif_\\miniconda3\\lib\\site-packages\\pandas\\core\\frame.py:8414\u001b[0m, in \u001b[0;36mDataFrame.pivot\u001b[1;34m(self, columns, index, values)\u001b[0m\n\u001b[0;32m   8409\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   8410\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_shared_docs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpivot\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   8411\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpivot\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, columns, index\u001b[38;5;241m=\u001b[39mlib\u001b[38;5;241m.\u001b[39mNoDefault, values\u001b[38;5;241m=\u001b[39mlib\u001b[38;5;241m.\u001b[39mNoDefault) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m   8412\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpivot\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pivot\n\u001b[1;32m-> 8414\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpivot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\saif_\\miniconda3\\lib\\site-packages\\pandas\\core\\reshape\\pivot.py:540\u001b[0m, in \u001b[0;36mpivot\u001b[1;34m(data, columns, index, values)\u001b[0m\n\u001b[0;32m    538\u001b[0m         index_list \u001b[38;5;241m=\u001b[39m [Series(data\u001b[38;5;241m.\u001b[39mindex, name\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mname)]\n\u001b[0;32m    539\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 540\u001b[0m     index_list \u001b[38;5;241m=\u001b[39m [data[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m com\u001b[38;5;241m.\u001b[39mconvert_to_list_like(index)]\n\u001b[0;32m    542\u001b[0m data_columns \u001b[38;5;241m=\u001b[39m [data[col] \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m columns_listlike]\n\u001b[0;32m    543\u001b[0m index_list\u001b[38;5;241m.\u001b[39mextend(data_columns)\n",
      "File \u001b[1;32mc:\\Users\\saif_\\miniconda3\\lib\\site-packages\\pandas\\core\\reshape\\pivot.py:540\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    538\u001b[0m         index_list \u001b[38;5;241m=\u001b[39m [Series(data\u001b[38;5;241m.\u001b[39mindex, name\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mname)]\n\u001b[0;32m    539\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 540\u001b[0m     index_list \u001b[38;5;241m=\u001b[39m [\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m com\u001b[38;5;241m.\u001b[39mconvert_to_list_like(index)]\n\u001b[0;32m    542\u001b[0m data_columns \u001b[38;5;241m=\u001b[39m [data[col] \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m columns_listlike]\n\u001b[0;32m    543\u001b[0m index_list\u001b[38;5;241m.\u001b[39mextend(data_columns)\n",
      "File \u001b[1;32mc:\\Users\\saif_\\miniconda3\\lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\saif_\\miniconda3\\lib\\site-packages\\pandas\\core\\indexes\\range.py:349\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[1;32m--> 349\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[0;32m    350\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Year'"
     ]
    }
   ],
   "source": [
    "# Create a new sheet for liquidity\n",
    "excel_file = Output_file  # Replace with your file path\n",
    "sheet_name = \"Liquidity_annual\"\n",
    "\n",
    "from Market_Cap import get_historical_data\n",
    "\n",
    "# Check if the sheet already exists and remove it\n",
    "with pd.ExcelWriter(excel_file, engine=\"openpyxl\", mode=\"a\", if_sheet_exists=\"replace\") as writer:\n",
    "    # Create an empty list for liquidity data\n",
    "    liquidity_data = []\n",
    "\n",
    "    # Iterate through each year\n",
    "    for year in range(2002, 2023):  # Adjusted the range to include 2022\n",
    "        # Extract closing prices for the last trading day of each year\n",
    "\n",
    "        # Iterate through each custom ticker\n",
    "        for ticker in tickers:\n",
    "            try:\n",
    "                stock_data = get_historical_data(ticker, f\"{year}-01-01\", f\"{year}-12-31\")\n",
    "                if stock_data is not None:\n",
    "                    daily_volume = stock_data[\"Volume\"]\n",
    "                    total_shares_outstanding = constituents_file.loc[constituents_file[\"ticker\"] == ticker, \"Share_outstanding\"].values[0]\n",
    "                    liquidity = daily_volume.sum() / total_shares_outstanding\n",
    "\n",
    "                    # Append a dictionary to the list\n",
    "                    liquidity_data.append({\"Ticker\": ticker, \"Liquidity\": liquidity, \"Year\": year})\n",
    "                else:\n",
    "                    print(f\"No data available for {ticker} in {year}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed download for {ticker}: {e}\")\n",
    "\n",
    "        # Convert the list to a DataFrame\n",
    "        liquidity_df = pd.DataFrame(liquidity_data)\n",
    "\n",
    "        # Pivot the DataFrame to have years in the first column and tickers in the header row\n",
    "        pivot_liquidity_df = liquidity_df.pivot(index='Year', columns='Ticker', values='Liquidity')\n",
    "\n",
    "        # Save the pivoted liquidity data for the year in a new sheet\n",
    "        pivot_liquidity_df.to_excel(writer, sheet_name=sheet_name, index=True, header=True)\n",
    "\n",
    "print(\"Liquidity data added to the Excel file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'liquidity' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mliquidity\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'liquidity' is not defined"
     ]
    }
   ],
   "source": [
    "liquidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed download for COR: 'str' object has no attribute 'loc'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CE: Data doesn't exist for startDate = 1009861200, endDate = 1041310800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed download for CE: 'str' object has no attribute 'loc'\n",
      "Failed download for HUM: 'str' object has no attribute 'loc'\n",
      "Failed download for CINF: 'str' object has no attribute 'loc'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KEYS: Data doesn't exist for startDate = 1009861200, endDate = 1041310800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed download for KEYS: 'str' object has no attribute 'loc'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NXPI: Data doesn't exist for startDate = 1009861200, endDate = 1041310800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed download for NXPI: 'str' object has no attribute 'loc'\n",
      "Failed download for BMY: 'str' object has no attribute 'loc'\n",
      "Failed download for EMR: 'str' object has no attribute 'loc'\n",
      "Failed download for CVS: 'str' object has no attribute 'loc'\n",
      "Failed download for RVTY: 'str' object has no attribute 'loc'\n",
      "Failed download for ES: 'str' object has no attribute 'loc'\n",
      "Failed download for DHI: 'str' object has no attribute 'loc'\n",
      "Failed download for ZBRA: 'str' object has no attribute 'loc'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KMI: Data doesn't exist for startDate = 1009861200, endDate = 1041310800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed download for KMI: 'str' object has no attribute 'loc'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INVH: Data doesn't exist for startDate = 1009861200, endDate = 1041310800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed download for INVH: 'str' object has no attribute 'loc'\n",
      "Failed download for GPC: 'str' object has no attribute 'loc'\n",
      "Failed download for SWKS: 'str' object has no attribute 'loc'\n",
      "Failed download for GIS: 'str' object has no attribute 'loc'\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Year'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m excel_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStock Data Output.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Replace with your file path\u001b[39;00m\n\u001b[0;32m      3\u001b[0m sheet_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLiquidity_annual\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 4\u001b[0m \u001b[43mcal_liquidity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mOutput_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtickers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstituents_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Projects\\Coding Projects\\Refined\\Financial Modelling-Yahoo Finance\\liquidity.py:35\u001b[0m, in \u001b[0;36mcal_liquidity\u001b[1;34m(excel_file, company_names, constituents_data, sheet_name)\u001b[0m\n\u001b[0;32m     32\u001b[0m liquidity_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(liquidity_data)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Pivot the DataFrame to have years in the first column and tickers in the header row\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m pivot_liquidity_df \u001b[38;5;241m=\u001b[39m \u001b[43mliquidity_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpivot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mYear\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTicker\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLiquidity\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Save the pivoted liquidity data for the year in a new sheet\u001b[39;00m\n\u001b[0;32m     38\u001b[0m pivot_liquidity_df\u001b[38;5;241m.\u001b[39mto_excel(writer, sheet_name\u001b[38;5;241m=\u001b[39msheet_name, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\saif_\\miniconda3\\lib\\site-packages\\pandas\\core\\frame.py:8414\u001b[0m, in \u001b[0;36mDataFrame.pivot\u001b[1;34m(self, columns, index, values)\u001b[0m\n\u001b[0;32m   8409\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   8410\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_shared_docs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpivot\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   8411\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpivot\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, columns, index\u001b[38;5;241m=\u001b[39mlib\u001b[38;5;241m.\u001b[39mNoDefault, values\u001b[38;5;241m=\u001b[39mlib\u001b[38;5;241m.\u001b[39mNoDefault) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m   8412\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpivot\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pivot\n\u001b[1;32m-> 8414\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpivot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\saif_\\miniconda3\\lib\\site-packages\\pandas\\core\\reshape\\pivot.py:540\u001b[0m, in \u001b[0;36mpivot\u001b[1;34m(data, columns, index, values)\u001b[0m\n\u001b[0;32m    538\u001b[0m         index_list \u001b[38;5;241m=\u001b[39m [Series(data\u001b[38;5;241m.\u001b[39mindex, name\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mname)]\n\u001b[0;32m    539\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 540\u001b[0m     index_list \u001b[38;5;241m=\u001b[39m [data[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m com\u001b[38;5;241m.\u001b[39mconvert_to_list_like(index)]\n\u001b[0;32m    542\u001b[0m data_columns \u001b[38;5;241m=\u001b[39m [data[col] \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m columns_listlike]\n\u001b[0;32m    543\u001b[0m index_list\u001b[38;5;241m.\u001b[39mextend(data_columns)\n",
      "File \u001b[1;32mc:\\Users\\saif_\\miniconda3\\lib\\site-packages\\pandas\\core\\reshape\\pivot.py:540\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    538\u001b[0m         index_list \u001b[38;5;241m=\u001b[39m [Series(data\u001b[38;5;241m.\u001b[39mindex, name\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mname)]\n\u001b[0;32m    539\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 540\u001b[0m     index_list \u001b[38;5;241m=\u001b[39m [\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m com\u001b[38;5;241m.\u001b[39mconvert_to_list_like(index)]\n\u001b[0;32m    542\u001b[0m data_columns \u001b[38;5;241m=\u001b[39m [data[col] \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m columns_listlike]\n\u001b[0;32m    543\u001b[0m index_list\u001b[38;5;241m.\u001b[39mextend(data_columns)\n",
      "File \u001b[1;32mc:\\Users\\saif_\\miniconda3\\lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\saif_\\miniconda3\\lib\\site-packages\\pandas\\core\\indexes\\range.py:349\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[1;32m--> 349\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[0;32m    350\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Year'"
     ]
    }
   ],
   "source": [
    "from liquidity import cal_liquidity\n",
    "excel_file = \"Stock Data Output.xlsx\"  # Replace with your file path\n",
    "sheet_name = \"Liquidity_annual\"\n",
    "cal_liquidity(Output_file, tickers, constituents_file, sheet_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating returns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using adjusted close prices at the annual, monthly, and daily frequencies, computing the annual, monthly, and daily returns. Saving them in new sheets labeled “Returns_annual”, “Returns_monthly”, and “Returns_daily”.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from returns import cal_returns\n",
    "\n",
    "cal_returns(Output_file, tickers, adj_price_data, start_date, end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating annual risks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using Returtns_daily, calculating the standard deviation of each stock in each year. Saving these in a new sheet called “Risk_annual”.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from risk import cal_risks\n",
    "\n",
    "cal_risks(Output_file, tickers, adj_price_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating statistics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calcuating summary statistics of our portfolio holdings (in sheet “Firm_Summary_Stat”)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beta import beta_main\n",
    "returns_sheet_name = 'Returns_annual'\n",
    "constituents_sheet_name = 'S&P 500 Constituent'\n",
    "\n",
    "returns_data = pd.read_excel(\n",
    "    Output_file, sheet_name=returns_sheet_name, index_col=0)\n",
    "constituents_data = pd.read_excel(\n",
    "    constituents_file, sheet_name=constituents_sheet_name, index_col=0)\n",
    "\n",
    "# Filter returns data for the last 5 years (2018:2022)\n",
    "returns_data_last_5_years = returns_data.loc['2018-01-01':'2022-12-31']\n",
    "\n",
    "# Create a new DataFrame for summary statistics\n",
    "summary_stats_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "# Calculate and add summary statistics for each firm\n",
    "summary_stats_df['Min'] = returns_data_last_5_years.min()\n",
    "summary_stats_df['Max'] = returns_data_last_5_years.max()\n",
    "summary_stats_df['Mean'] = returns_data_last_5_years.mean()\n",
    "summary_stats_df['Volatility'] = returns_data_last_5_years.std()\n",
    "\n",
    "# Load market capitalization data\n",
    "market_cap_data = pd.read_excel(\n",
    "    Output_file, sheet_name=\"Market_Cap\", index_col=0)\n",
    "\n",
    "# Add market capitalization (size) for each firm to the summary_stats_df\n",
    "# You can use mean() or any other aggregation method\n",
    "summary_stats_df['Size'] = market_cap_data.mean()\n",
    "\n",
    "\n",
    "# Add industry information for each firm\n",
    "summary_stats_df['Industry'] = constituents_data['GICS Sector']\n",
    "\n",
    "# Add a new sheet \"Firm_Summary_Stat\" to the existing Excel file\n",
    "with pd.ExcelWriter(Output_file, engine=\"openpyxl\", mode=\"a\", if_sheet_exists=\"replace\") as writer:\n",
    "    summary_stats_df.T.to_excel(\n",
    "        writer, sheet_name=\"Firm_Summary_Stat\", index=True, header=True)\n",
    "\n",
    "\n",
    "beta_main(tickers, start_date, end_date,\n",
    "          constituents_file, Output_file, summary_stats_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Personal Portfolio Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Strategy = Return: Every January, invest more in firms that had a larger return last year. If they had negative returns, do not invest in them this year.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from portfolio_analysis import cal_portfolio\n",
    "\n",
    "combined_returns, Rf = cal_portfolio(tickers, adj_price_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating portfolio performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from portfolio_perf import cal_portfolio_perf\n",
    "\n",
    "cal_portfolio_perf(combined_returns, Rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Portfolio Returns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from portfolio_return import cal_portfolio_return\n",
    "\n",
    "cal_portfolio_return(combined_returns, Rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating investment summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from invest_sum import cal_invest_sum\n",
    "\n",
    "cal_invest_sum(tickers, Rf, combined_returns, constituents_file, Output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making excel file more readalbe.\n",
    "\n",
    "###### (This is the last step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wraping Text\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
